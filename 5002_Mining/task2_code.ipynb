{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Application of Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Constructing a Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: ALL files under the KnowledgeGraph folder\n",
    "\n",
    "Description: \n",
    "\n",
    "1. To construct a knowledge graph, you will need to use Python and Neo4j database. \n",
    "2. To create the knowledge graph, you should install the Neo4j graph database on your computer and use Python to connect to it. \n",
    "3. Then, you can construct the knowledge graph based on the input files. \n",
    "4. Please search for relevant content on your own. In the knowledge graph you build, the node type is \"company,\" and there are six types of edges: \"compete,\" \"cooperate,\" \"dispute,\" \"invest,\" \"same_industry,\" and \"supply.\" Edges can be directed, meaning from S to P, or undirected (bidirectional).\n",
    "\n",
    "Submission (10 marks): You should document the process, and plot the knowledge graph in your report.pdf file. For detailed requirements, please refer to Appendix 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1-2 Python and Neo4j database initialisation\n",
    "1. import packages and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install neo4j\n",
    "# %pip install py2neo\n",
    "from py2neo import Graph, Subgraph, Node, Relationship\n",
    "import neo4j\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful\n"
     ]
    }
   ],
   "source": [
    "# credentials\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"  # Replace with your Neo4j username\n",
    "password = \"mining5002\"\n",
    "uri2 = 'http://localhost:7474'\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "try: \n",
    "    graph = Graph(uri, auth = (username, password))\n",
    "    print('successful')\n",
    "except Exception as e:\n",
    "    print(f'error: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read data from CSV files\n",
    "df_nodes = pd.read_csv(\"data/KnowledgeGraph/hidy.nodes.company.csv\")\n",
    "df_compete = pd.read_csv(\"data/KnowledgeGraph/hidy.relationships.compete.csv\")\n",
    "df_cooperate = pd.read_csv(\"data/KnowledgeGraph/hidy.relationships.cooperate.csv\")\n",
    "df_dispute = pd.read_csv(\"data/KnowledgeGraph/hidy.relationships.dispute.csv\")\n",
    "df_invest = pd.read_csv(\"data/KnowledgeGraph/hidy.relationships.invest.csv\")\n",
    "df_same_industry = pd.read_csv(\"data/KnowledgeGraph/hidy.relationships.same_industry.csv\")\n",
    "df_supply = pd.read_csv(\"data/KnowledgeGraph/hidy.relationships.supply.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of df_nodes:\n",
      "   :ID company_name       code   :LABEL\n",
      "0    0         东诚药业  002675.SZ  company\n",
      "1    1         大庆华科  000985.SZ  company\n",
      "2    2         恒辉安防  300952.SZ  company\n",
      "\n",
      "Head of df_compete:\n",
      "   :START_ID  :END_ID    :TYPE             time\n",
      "0       2082     2287  compete   2020/4/9 13:33\n",
      "1       3348      272  compete  2018/10/29 7:16\n",
      "2       1431      707  compete   2021/5/17 8:01\n",
      "\n",
      "Head of df_cooperate:\n",
      "   :START_ID  :END_ID      :TYPE             time\n",
      "0       2197      245  cooperate  2019/9/17 12:00\n",
      "1       1165      756  cooperate   2020/8/2 17:10\n",
      "2       2082     2899  cooperate   2019/9/2 17:42\n",
      "\n",
      "Head of df_dispute:\n",
      "   :START_ID  :END_ID    :TYPE              time\n",
      "0       1605     1866  dispute  2020/12/17 16:55\n",
      "1       1299     1136  dispute   2022/2/22 17:55\n",
      "2       2508     3950  dispute    2022/1/19 8:11\n",
      "\n",
      "Head of df_invest:\n",
      "   :START_ID  :END_ID   :TYPE\n",
      "0       1165     1478  invest\n",
      "1        469     3116  invest\n",
      "2       3566     2272  invest\n",
      "\n",
      "Head of df_same_industry:\n",
      "   :START_ID  :END_ID          :TYPE             time\n",
      "0       2197     3775  same_industry  2021/3/18 20:56\n",
      "1       1165     1571  same_industry  2020/1/10 19:58\n",
      "2       2082      262  same_industry  2019/8/30 11:25\n",
      "\n",
      "Head of df_supply:\n",
      "   :START_ID  :END_ID   :TYPE\n",
      "0       1165      951  supply\n",
      "1       2082      707  supply\n",
      "2       2082      561  supply\n"
     ]
    }
   ],
   "source": [
    "print(\"Head of df_nodes:\")\n",
    "print(df_nodes.head(3))\n",
    "\n",
    "print(\"\\nHead of df_compete:\")\n",
    "print(df_compete.head(3))\n",
    "\n",
    "print(\"\\nHead of df_cooperate:\")\n",
    "print(df_cooperate.head(3))\n",
    "\n",
    "print(\"\\nHead of df_dispute:\")\n",
    "print(df_dispute.head(3))\n",
    "\n",
    "print(\"\\nHead of df_invest:\")\n",
    "print(df_invest.head(3))\n",
    "\n",
    "print(\"\\nHead of df_same_industry:\")\n",
    "print(df_same_industry.head(3))\n",
    "\n",
    "print(\"\\nHead of df_supply:\")\n",
    "print(df_supply.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. writing sessions, creating nodes and relationships for all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create nodes\n",
    "def create_nodes(session, df):\n",
    "    for index, row in df.iterrows():\n",
    "        query = (\n",
    "            f\"CREATE (n:company {{ID: {row[':ID']}, company_name: '{row['company_name']}', code: '{row['code']}'}})\"\n",
    "        )\n",
    "        session.run(query)\n",
    "\n",
    "# create relationship\n",
    "def create_relationships(session, df, relationship_type):\n",
    "    for index, row in df.iterrows():\n",
    "        query = (\n",
    "            f\"MATCH (a:company {{ID: {row[':START_ID']}}})\"\n",
    "            f\"MATCH (b:company {{ID: {row[':END_ID']}}})\"\n",
    "        )\n",
    "        if 'time' in row:  # Check if 'time' column exists in the dataframe\n",
    "            query += f\"CREATE (a)-[:{relationship_type} {{time: '{row['time']}'}}]->(b)\"\n",
    "        else:\n",
    "            query += f\"CREATE (a)-[:{relationship_type}]->(b)\"\n",
    "        session.run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    create_nodes(session, df_nodes)\n",
    "\n",
    "# Create relationships for each dataframe\n",
    "def create_all_relationships():\n",
    "    with driver.session() as session:\n",
    "        create_relationships(session, df_compete, \"compete\")\n",
    "        create_relationships(session, df_cooperate, \"cooperate\")\n",
    "        create_relationships(session, df_dispute, \"dispute\")\n",
    "        create_relationships(session, df_invest, \"invest\")\n",
    "        create_relationships(session, df_same_industry, \"same_industry\")\n",
    "        create_relationships(session, df_supply, \"supply\")\n",
    "\n",
    "# Call the function to create all relationships\n",
    "create_all_relationships()\n",
    "\n",
    "# Close the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3-4 graph database query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute Cypher query\n",
    "def execute_query(query):\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        result = session.run(query)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cindy\\AppData\\Local\\Temp\\ipykernel_20504\\386232654.py:3: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session(database=\"neo4j\") as session:\n"
     ]
    }
   ],
   "source": [
    "## Merge 'compete' and 'cooperate', 'invest', 'supply' relationships, creating a new relationship 'cooperate_invest_supply':\n",
    "cypher_query = \"\"\"\n",
    "MATCH (a:company)-[r1:compete]-(b:company)\n",
    "MATCH (a)-[r2]-(b)\n",
    "WHERE type(r2) IN ['cooperate', 'invest', 'supply']\n",
    "WITH a, b, COLLECT(r2) AS relationships\n",
    "FOREACH (rel IN relationships | CREATE (a)-[:cooperate_invest_supply]->(b) DELETE rel)\n",
    "RETURN a, b;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Cypher query\n",
    "result = execute_query(cypher_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the company with the most 'cooperate' relationships and return the company and its 'cooperate' relationships:\n",
    "cypher_query = \"\"\"\n",
    "MATCH (node:company)-[r:cooperate]->(otherNode)\n",
    "WITH node, COUNT(r) AS incomingCount, COLLECT(r) AS relationships\n",
    "ORDER BY incomingCount DESC\n",
    "LIMIT 1\n",
    "RETURN node, relationships;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Cypher query\n",
    "result = execute_query(cypher_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve information for a specific company with code \"300750.SZ\", company_name \"宁德时代\", and ID 743:\n",
    "cypher_query = \"\"\"\n",
    "MATCH (c:company {code: \"300750.SZ\", company_name: \"宁德时代\", ID: 743})-[r]-(connectedNode)\n",
    "RETURN c, r, connectedNode;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Cypher query\n",
    "result = execute_query(cypher_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the top 5 suppliers based on the number of 'supply' relationships:\n",
    "cypher_query = \"\"\"\n",
    "MATCH (supplier:company)-[r:supply]->(customer:company)\n",
    "WITH supplier, COUNT(r) AS outgoingSupplyCount\n",
    "ORDER BY outgoingSupplyCount DESC\n",
    "LIMIT 5\n",
    "RETURN supplier, outgoingSupplyCount;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Cypher query\n",
    "result = execute_query(cypher_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find companies involved in disputes with more than 1 dispute relationship, and return the top 5:\n",
    "cypher_query = \"\"\"\n",
    "MATCH (entity:company)-[r:dispute]->()\n",
    "WITH entity, COUNT(r) AS disputeCount\n",
    "WHERE disputeCount > 1\n",
    "RETURN entity, disputeCount\n",
    "ORDER BY disputeCount DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the Cypher query\n",
    "result = execute_query(cypher_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Knowledge-Driven Financial Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE will first make a database that list out the relationships between companies by concatenating all data. We separate two implicit effects of sentiment ( compete and dispute), and the other four together to remove redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 association database curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'time' column from each dataframe\n",
    "df_compete = df_compete.drop('time', axis=1)\n",
    "df_cooperate = df_cooperate.drop('time', axis=1)\n",
    "df_dispute = df_dispute.drop('time', axis=1)\n",
    "df_same_industry = df_same_industry.drop('time', axis=1)\n",
    "# Concatenate 'df_compete' and 'df_dispute' together\n",
    "df_oppo = pd.concat([df_compete, df_dispute])\n",
    "\n",
    "# Concatenate the other four dataframes together\n",
    "df_tgt = pd.concat([df_cooperate, df_invest, df_same_industry, df_supply])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to separate into two case, of opposite effect and unidirectional effect. \n",
    "Here we reverse the columns to record the bidirectional effect upon each other. Te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464, 3)\n",
      "(11202, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_oppo.shape)\n",
    "print(df_tgt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(928, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select only the relevant columns\n",
    "df_oppo_bidir = df_oppo[[':START_ID', ':END_ID']].copy()\n",
    "\n",
    "# Create a copy with reversed start and end ids\n",
    "df_reverse = df_oppo[[':END_ID', ':START_ID']].copy()\n",
    "df_reverse.columns = [':START_ID', ':END_ID']\n",
    "\n",
    "# Concatenate the original and reversed dataframes\n",
    "df_oppo_bidir = pd.concat([df_oppo_bidir, df_reverse])\n",
    "\n",
    "\n",
    "# Display the bidirectional dataframe shape\n",
    "print(df_oppo_bidir.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys: 507\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary to store relationships\n",
    "relation_oppo_dict = {}\n",
    "\n",
    "# Iterate through the dataframe and populate the dictionary\n",
    "for index, row in df_oppo_bidir.iterrows():\n",
    "    start_id = row[':START_ID']\n",
    "    end_id = row[':END_ID']\n",
    "\n",
    "    # Add start_id to the dictionary if not present\n",
    "    if start_id not in relation_oppo_dict:\n",
    "        relation_oppo_dict[start_id] = []\n",
    "\n",
    "    # Add end_id to the list of related companies for the start_id\n",
    "    relation_oppo_dict[start_id].append(end_id)\n",
    "\n",
    "# Display the number of keys in the relationships dictionary\n",
    "print(\"Number of keys:\", len(relation_oppo_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THerefore, ther are 507 companies involved in compete / dispute relationships.\n",
    "Now we do the same treatment on the ones with syngestic effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17407, 2)\n"
     ]
    }
   ],
   "source": [
    "# Select only the relevant columns\n",
    "df_tgt_bidir = df_tgt[[':START_ID', ':END_ID']].copy()\n",
    "\n",
    "# Create a copy with reversed start and end ids\n",
    "df_reverse = df_tgt[[':END_ID', ':START_ID']].copy()\n",
    "df_reverse.columns = [':START_ID', ':END_ID']\n",
    "\n",
    "# Concatenate the original and reversed dataframes\n",
    "df_tgt_bidir = pd.concat([df_tgt_bidir, df_reverse])\n",
    "\n",
    "# Drop duplicate rows (keeping only distinct pairs of start and end ids)\n",
    "df_tgt_bidir = df_tgt_bidir.drop_duplicates(subset=[':START_ID', ':END_ID'])\n",
    "\n",
    "# Display the bidirectional dataframe shape\n",
    "print(df_tgt_bidir.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys: 3448\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is named 'df'\n",
    "# Create an empty dictionary to store relationships\n",
    "relation_tgt_dict = {}\n",
    "\n",
    "# Iterate through the dataframe and populate the dictionary\n",
    "for index, row in df_tgt_bidir.iterrows():\n",
    "    start_id = row[':START_ID']\n",
    "    end_id = row[':END_ID']\n",
    "\n",
    "    # Add start_id to the dictionary if not present\n",
    "    if start_id not in relation_tgt_dict:\n",
    "        relation_tgt_dict[start_id] = []\n",
    "\n",
    "    # Add end_id to the list of related companies for the start_id\n",
    "    relation_tgt_dict[start_id].append(end_id)\n",
    "\n",
    "# Display the number of keys in the relationships dictionary\n",
    "print(\"Number of keys:\", len(relation_tgt_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At most 3448 + 505 = 3955 companies, out of 3974 companies, have at least established 1 relationship with another company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中兴通讯: ['杰瑞股份', '中国电信']\n",
      "中国平安: ['春光科技', '华夏幸福', '贵州茅台', '中国银行']\n",
      "分众传媒: ['光线传媒', '中国联通']\n",
      "贵州茅台: ['宁德时代', '山西汾酒', '中国平安', '贵绳股份']\n",
      "宁德时代: ['永福股份', '贵州茅台', '易事特', '赣锋锂业', '智飞生物', '东方精工', '众泰汽车', '华自科技', '温氏股份', '沧州明珠', '先惠技术']\n",
      "创新医疗: ['光大银行', '药明康德']\n",
      "江铃汽车: ['中国神华']\n",
      "赣锋锂业: ['宁德时代', '江特电机']\n",
      "通威股份: ['迈为股份']\n",
      "华创阳安: ['京东方']\n"
     ]
    }
   ],
   "source": [
    "# Rename the dictionary\n",
    "name_oppo_dict = {df_nodes.at[k, 'company_name']: [df_nodes.at[v, 'company_name'] for v in vs] for k, vs in relation_oppo_dict.items()}\n",
    "name_oppo_dict = {key: list(set(values)) for key, values in name_oppo_dict.items()}\n",
    "\n",
    "# Print the first 10 values of name_oppo_dict\n",
    "for key, value in list(name_oppo_dict.items())[:10]:\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "红宝丽: ['航锦科技', '滨化股份']\n",
      "浙富控股: ['东方电气', '华凯创意', '二三四五', '长江电力', '葛洲坝', '汇通能源']\n",
      "中兴通讯: ['长盈精密', '平安银行', '宜通世纪', '光迅科技', '国电南自', '移为通信', '海康威视', '中国石油', '容知日新', '辰安科技', '烽火通信', '宁德时代', '中国平安', '中国电信', '光大银行', '工业富联', '闻泰科技', '劲拓股份', '深圳华强', '鹏辉能源', '三一重工', '恩捷股份', '天迈科技', '新松机器人', '中国长城', '中信银行', '中国卫通', '寒武纪', '广电网络', '中国银行', '上汽集团', '天津港', '高新兴', '特发信息', '万马科技', '黑芝麻', '万马股份', '紫光股份', '格力电器', '千方科技', '比亚迪', '中光防雷', '智慧能源', '华泰证券', '美亚光电', '金智科技', '博创科技', '光华科技', '同有科技', '长安汽车', '国泰君安', '三七互娱', '苏交科', '北京银行', '顺络电子', '格尔软件', '民德电子', '中信证券', '春兴精工', '宣亚国际', '世纪华通', '聚飞光电', '中国联通', '佳都科技', '大中矿业', '博威合金', '上海银行', '中集集团', '民生银行', '中国石化', '浙大网新', '东风汽车', '许继电气', '兴民智通', '安科瑞', '奇安信', '建设银行', '国新文化', '紫金矿业', '赣锋锂业', '大唐电信', '梦网集团', '崇达技术', '温氏股份', '光峰科技', '贵州茅台', '亚光科技', '京东方', '新凤鸣', '天神娱乐', '创意信息', '国金证券', '交通银行', '招商证券']\n",
      "潜能恒信: ['中国石油', '石化机械', '广电运通', '恒泰艾普']\n",
      "小康股份: ['宁德时代', '工商银行', '飞龙股份', '东风汽车', '安徽合力', '中信建投', '比亚迪']\n",
      "仁东控股: ['济民制药', '兴业银行', '永鼎股份', '姚记扑克']\n",
      "卧龙地产: ['浙江龙盛']\n",
      "江苏阳光: ['合盛硅业', '上机数控', '四川长虹', '东阳光']\n",
      "广电运通: ['宁德时代', '卓翼科技', '东方国信', '中信银行', '工商银行', '潜能恒信', '恒生电子', '恒宝股份', '兴业银行', '长沙银行', '农业银行', '广电计量', '赛隆药业', '民生银行', '奇安信', '御银股份', '建设银行', '中科信息']\n",
      "比亚迪: ['睿创微纳', '工商银行', '博俊科技', '青岛港', '雷科防务', '天风证券', '*ST盐湖', '中信建投', '迈瑞医疗', '泉峰汽车', '合纵科技', '中金公司', '日上集团', '凌云股份', '海天味业', '美力科技', '鸿利智汇', '中国石油', '中银证券', '海通证券', '海达股份', '国新能源', '科大国创', '德尔股份', '华昌达', '湘潭电化', '海能达', '宁德时代', '延安必康', '常铝股份', '壹石通', '中国平安', '恒铭达', '长鹰信质', '华菱钢铁', '盈趣科技', '德迈仕', '工业富联', '水晶光电', '伊之密', '奥特迅', '中京电子', '超声电子', '新亚电子', '德方纳米', '深圳华强', '维宏股份', '海泰科', '广汽集团', '赢合科技', '三花智控', '信测标准', '鹏辉能源', '众业达', '杉杉股份', '津荣天宇', '上海新阳', '天赐材料', '华讯方舟', '曙光股份', '英洛华', '湘油泵', '中国动力', '北方华创', '三安光电', '北汽蓝谷', '博敏电子', '上海沿浦', '老板电器', '中国重汽', '天迈科技', '纳尔股份', '永贵电器', '嵘泰股份', '安井食品', '凯龙高科', '国轩高科', '中国银河', '绿盟科技', '慈星股份', '瑞松科技', '福耀玻璃', '扬杰科技', '国机汽车', '蓝思科技', '广州港', '春晖智控', '广汇汽车', '回天新材', '力源信息', '中国神华', '凯中精密', '科达利', '士兰微', '立讯精密', '万安科技', '富瀚微', '德赛西威', '贝斯特', '川环科技', '中国银行', '卡倍亿', '初灵信息', '恒帅股份', '太钢不锈', '天合光能', '王子新材', '福立旺', '星帅尔', '国安达', '上汽集团', '光洋股份', '宜安科技', '丰元股份', '中节能太阳能', '金风科技', '腾龙股份', '锐科激光', '中通客车', '招商银行', '硅宝科技', '蓝海华腾', '欣旺达', '今天国际', '中国软件', '格力电器', '华友钴业', '太平洋证券', '双汇发展', '鞍钢股份', '福达股份', '智慧能源', '中钢天源', '奥特佳', '雷赛智能', '科翔股份', '奥联电子', '东方集团', '中国汽研', '多氟多', '万通智控', '长安汽车', '京泉华', '格林美', '登云股份', '豪能股份', '集泰股份', '国泰君安', '一汽轿车', '天际股份', '富临精工', '金发科技', '之江生物', '汇顶科技', '民德电子', '中国铁建', '中能电气', '先导智能', '塞力斯', '中信证券', '云南白药', '越博动力', '松原股份', '隆基机械', '玲珑轮胎', '孚能科技', '深圳机场', '四川路桥', '世纪华通', '横店东磁', '佳都科技', '信维通信', '和科达', '宇瞳光学', '海量数据', '松井股份', '华贸物流', '莱宝高科', '广东鸿图', '万向钱潮', '深科技', '众泰汽车', '秋田微', '胜宏科技', '卧龙电驱', '香山股份', '和而泰', '长信科技', '嘉寓股份', '和胜股份', '金博股份', '盾安环境', '斯达半导', '龙蟠科技', '万科A', '均胜电子', '银河微电', '东方电热', '中国石化', '当升科技', '安利股份', '交控科技', '中国船舶', '新莱应材', '东风汽车', '南京聚隆', '星源材质', '高盟新材', '每日互动', '江淮汽车', '建设银行', '松芝股份', '恒久科技', '飞荣达', '惠伦晶体', '赣锋锂业', '中兴通讯', '伊戈尔', '合力泰', '华西证券', '中鼎股份', '天龙股份', '中科电气', '星云股份', '长城汽车', '融捷股份', '道氏技术', '光峰科技', '新宙邦', '朗进科技', '潍柴动力', '小康股份', '万丰奥威', '光弘科技', '贵州茅台', '天奇股份', '金固股份', '昊志机电', '中顺洁柔', '杭可科技', '万顺新材', '天齐锂业', '科大讯飞', '文灿股份', '华大基因', '宇环数控', '银轮股份', '凯迪股份', '中科创达', '一汽夏利']\n"
     ]
    }
   ],
   "source": [
    "name_tgt_dict = {df_nodes.at[k, 'company_name']: [df_nodes.at[v, 'company_name'] for v in vs] for k, vs in relation_tgt_dict.items()}\n",
    "# make it distinct\n",
    "name_tgt_dict = {key: list(set(values)) for key, values in name_tgt_dict.items()}\n",
    "\n",
    "# Print the first 10 values of relation_tgt_dict\n",
    "for key, value in list(name_tgt_dict.items())[:10]:\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in relation_oppo_dict: 0\n",
      "Number of NaN values in relation_tgt_dict: 0\n",
      "NaN count in name_oppo_dict: 0\n",
      "NaN count in name_tgt_dict: 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Check for NaN values in relation_oppo_dict\n",
    "nan_count_oppo = sum(math.isnan(val) if isinstance(val, (float, int)) else np.isnan(val).any() for val in relation_oppo_dict.values())\n",
    "nan_count_tgt = sum(math.isnan(val) if isinstance(val, (float, int)) else np.isnan(val).any() for val in relation_tgt_dict.values())\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of NaN values in relation_oppo_dict: {nan_count_oppo}\")\n",
    "print(f\"Number of NaN values in relation_tgt_dict: {nan_count_tgt}\")\n",
    "import math\n",
    "\n",
    "def count_nan(dictionary):\n",
    "    nan_count = 0\n",
    "    for values in dictionary.values():\n",
    "        for value in values:\n",
    "            if isinstance(value, float) and math.isnan(value):\n",
    "                nan_count += 1\n",
    "    return nan_count\n",
    "\n",
    "# Assuming name_oppo_dict and name_tgt_dict are your dictionaries\n",
    "nan_count_oppo = count_nan(name_oppo_dict)\n",
    "nan_count_tgt = count_nan(name_tgt_dict)\n",
    "\n",
    "print(f'NaN count in name_oppo_dict: {nan_count_oppo}')\n",
    "print(f'NaN count in name_tgt_dict: {nan_count_tgt}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save relation_oppo_dict to a file\n",
    "with open('others/checkpoints/name_oppo_dict.json', 'w') as oppo_file:\n",
    "    json.dump(name_oppo_dict, oppo_file, indent=2)\n",
    "\n",
    "# Save relation_tgt_dict to a file\n",
    "with open('others/checkpoints/name_tgt_dict.json', 'w') as tgt_file:\n",
    "    json.dump(name_tgt_dict, tgt_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 matching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the curated database name_tgt_dict and name_oppo_dict for implicit association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NewsID                                        NewsContent Explicit_Company  \\\n",
      "0       1  　　本报记者 田雨 李京华    　　中国建设银行股份有限公司原董事长张恩照受贿案３日一审宣...             建设银行   \n",
      "1       2  　　中国农业银行信用卡中心由北京搬到上海了！  　　农行行长杨明生日前在信用卡中心揭牌仪式上...             农业银行   \n",
      "\n",
      "   label  \n",
      "0      0  \n",
      "1      1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/cindy/OneDrive - HKUST (Guangzhou)/Mining/assignment/dsaa5002_project/5002Project_50015720_/Task1.xlsx')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NewsID                                        NewsContent Explicit_Company  \\\n",
      "0       1  　　本报记者 田雨 李京华    　　中国建设银行股份有限公司原董事长张恩照受贿案３日一审宣...             建设银行   \n",
      "1       2  　　中国农业银行信用卡中心由北京搬到上海了！  　　农行行长杨明生日前在信用卡中心揭牌仪式上...             农业银行   \n",
      "2       3  　　在新基金快速发行以及申购资金回流的情况下，市场总体上呈现资金流动性过剩格局，考虑到现阶段...        外运发展,中国国航   \n",
      "\n",
      "   label                          Implicit_Positive_Company  \\\n",
      "0      0                                          任子行, 捷捷微电   \n",
      "1      1  东方财富, 神州数码, 山东矿机, 工商银行, 成都银行, 金地集团, 中信建投, 中科曙光...   \n",
      "2      1  中国外运, 南方航空, 工商银行, 山航B, 中国卫通, 吉祥航空, 兴业证券, 寒武纪, ...   \n",
      "\n",
      "                           Implicit_Negative_Company  \n",
      "0  航天信息, 怡亚通, 工商银行, 聚龙股份, 平安银行, 晨鸣纸业, 中金公司, 民生银行,...  \n",
      "1                                               ST云维  \n",
      "2                                                     \n"
     ]
    }
   ],
   "source": [
    "df['Implicit_Positive_Company'] = ''\n",
    "df['Implicit_Negative_Company'] = ''\n",
    "\n",
    "# Update the columns based on label values\n",
    "for index, row in df.iterrows():\n",
    "    explicit_companies = row['Explicit_Company'].split(',') if pd.notnull(row['Explicit_Company']) else []\n",
    "    label = row['label']\n",
    "\n",
    "    implicit_positive_companies = []\n",
    "    implicit_negative_companies = []\n",
    "\n",
    "    for company in explicit_companies:\n",
    "        implicit_positive_companies.extend(name_oppo_dict.get(company, []))\n",
    "        implicit_negative_companies.extend(name_tgt_dict.get(company, []))\n",
    "\n",
    "    if label == 0:\n",
    "        df.at[index, 'Implicit_Positive_Company'] = ', '.join(implicit_positive_companies)\n",
    "        df.at[index, 'Implicit_Negative_Company'] = ', '.join(implicit_negative_companies)\n",
    "    elif label == 1:\n",
    "        df.at[index, 'Implicit_Positive_Company'] = ', '.join(implicit_negative_companies)\n",
    "        df.at[index, 'Implicit_Negative_Company'] = ', '.join(implicit_positive_companies)\n",
    "\n",
    "# Print the first 3 rows of the updated DataFrame\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission format for empty input\n",
    "df['Implicit_Positive_Company'].replace('', 'None', inplace=True)\n",
    "df['Implicit_Negative_Company'].replace('', 'None', inplace=True)\n",
    "\n",
    "df.to_excel('Task2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsID</th>\n",
       "      <th>NewsContent</th>\n",
       "      <th>Explicit_Company</th>\n",
       "      <th>label</th>\n",
       "      <th>Implicit_Positive_Company</th>\n",
       "      <th>Implicit_Negative_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>本报记者 田雨 李京华    　　中国建设银行股份有限公司原董事长张恩照受贿案３日一审宣...</td>\n",
       "      <td>建设银行</td>\n",
       "      <td>0</td>\n",
       "      <td>任子行, 捷捷微电</td>\n",
       "      <td>航天信息, 怡亚通, 工商银行, 聚龙股份, 平安银行, 晨鸣纸业, 中金公司, 民生银行,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>中国农业银行信用卡中心由北京搬到上海了！  　　农行行长杨明生日前在信用卡中心揭牌仪式上...</td>\n",
       "      <td>农业银行</td>\n",
       "      <td>1</td>\n",
       "      <td>东方财富, 神州数码, 山东矿机, 工商银行, 成都银行, 金地集团, 中信建投, 中科曙光...</td>\n",
       "      <td>ST云维</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>在新基金快速发行以及申购资金回流的情况下，市场总体上呈现资金流动性过剩格局，考虑到现阶段...</td>\n",
       "      <td>外运发展,中国国航</td>\n",
       "      <td>1</td>\n",
       "      <td>中国外运, 南方航空, 工商银行, 山航B, 中国卫通, 吉祥航空, 兴业证券, 寒武纪, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>胜利股份（000407）公司子公司填海造地2800亩，以青岛的地价估算，静态价值在10亿...</td>\n",
       "      <td>胜利股份</td>\n",
       "      <td>1</td>\n",
       "      <td>新疆浩源, 特锐德</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>由于全球最大的俄罗斯Uralkaly钾矿被淹，产量大减，同时满洲里口岸铁路在修复线，导致...</td>\n",
       "      <td>冠农股份</td>\n",
       "      <td>1</td>\n",
       "      <td>藏格控股, 西部黄金, 南宁百货, 富邦股份</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473680</th>\n",
       "      <td>1037031</td>\n",
       "      <td>每经AI快讯，有投资者在投资者互动平台提问：请问公司目前有没有电解槽产能，规划情况能否详细介...</td>\n",
       "      <td>亿华通</td>\n",
       "      <td>1</td>\n",
       "      <td>东旭光电, 中国船舶, 飞龙股份, 东风汽车, 福田汽车, 百奥泰, 宝泰隆, 仕佳光子</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473681</th>\n",
       "      <td>1037032</td>\n",
       "      <td>依米康（SZ 300249，收盘价：10.38元）发布公告称，2023年10月12日，依米康...</td>\n",
       "      <td>中泰证券,依米康</td>\n",
       "      <td>1</td>\n",
       "      <td>东北证券, 智飞生物, 五粮液, 史丹利, 中信建投, 国泰君安, 中金公司, 长江证券, ...</td>\n",
       "      <td>华谊嘉信, 西水股份</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473682</th>\n",
       "      <td>1037033</td>\n",
       "      <td>天风证券10月13日发布研报称，给予中核科技（000777.SZ，最新价：13.03元）买入...</td>\n",
       "      <td>中核科技,天风证券</td>\n",
       "      <td>1</td>\n",
       "      <td>中国核电, 东北证券, 恒生电子, 浙商证券, 中信建投, 迈瑞医疗, 国泰君安, 中金公司...</td>\n",
       "      <td>三特索道, 中源家居, 吉翔股份</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473683</th>\n",
       "      <td>1037034</td>\n",
       "      <td>有投资者提问：抗癌药CPT获批后，公司是否应该按照股权协议继续收购沙东股权，适应症为MM的C...</td>\n",
       "      <td>海特生物</td>\n",
       "      <td>1</td>\n",
       "      <td>药明康德, 海尔生物</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473684</th>\n",
       "      <td>1037035</td>\n",
       "      <td>10月13日午间，根据恩捷股份发布的公告，持有公司股份5%以上的股东玉溪合益投资有限公司（下...</td>\n",
       "      <td>恩捷股份</td>\n",
       "      <td>1</td>\n",
       "      <td>宁德时代, 亿纬锂能, 胜利精密, 中兴通讯, 平安银行, 文科园林, 天赐材料, 云南白药...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473685 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NewsID                                        NewsContent  \\\n",
       "0             1  　　本报记者 田雨 李京华    　　中国建设银行股份有限公司原董事长张恩照受贿案３日一审宣...   \n",
       "1             2  　　中国农业银行信用卡中心由北京搬到上海了！  　　农行行长杨明生日前在信用卡中心揭牌仪式上...   \n",
       "2             3  　　在新基金快速发行以及申购资金回流的情况下，市场总体上呈现资金流动性过剩格局，考虑到现阶段...   \n",
       "3             4  　　胜利股份（000407）公司子公司填海造地2800亩，以青岛的地价估算，静态价值在10亿...   \n",
       "4             8  　　由于全球最大的俄罗斯Uralkaly钾矿被淹，产量大减，同时满洲里口岸铁路在修复线，导致...   \n",
       "...         ...                                                ...   \n",
       "473680  1037031  每经AI快讯，有投资者在投资者互动平台提问：请问公司目前有没有电解槽产能，规划情况能否详细介...   \n",
       "473681  1037032  依米康（SZ 300249，收盘价：10.38元）发布公告称，2023年10月12日，依米康...   \n",
       "473682  1037033  天风证券10月13日发布研报称，给予中核科技（000777.SZ，最新价：13.03元）买入...   \n",
       "473683  1037034  有投资者提问：抗癌药CPT获批后，公司是否应该按照股权协议继续收购沙东股权，适应症为MM的C...   \n",
       "473684  1037035  10月13日午间，根据恩捷股份发布的公告，持有公司股份5%以上的股东玉溪合益投资有限公司（下...   \n",
       "\n",
       "       Explicit_Company  label  \\\n",
       "0                  建设银行      0   \n",
       "1                  农业银行      1   \n",
       "2             外运发展,中国国航      1   \n",
       "3                  胜利股份      1   \n",
       "4                  冠农股份      1   \n",
       "...                 ...    ...   \n",
       "473680              亿华通      1   \n",
       "473681         中泰证券,依米康      1   \n",
       "473682        中核科技,天风证券      1   \n",
       "473683             海特生物      1   \n",
       "473684             恩捷股份      1   \n",
       "\n",
       "                                Implicit_Positive_Company  \\\n",
       "0                                               任子行, 捷捷微电   \n",
       "1       东方财富, 神州数码, 山东矿机, 工商银行, 成都银行, 金地集团, 中信建投, 中科曙光...   \n",
       "2       中国外运, 南方航空, 工商银行, 山航B, 中国卫通, 吉祥航空, 兴业证券, 寒武纪, ...   \n",
       "3                                               新疆浩源, 特锐德   \n",
       "4                                  藏格控股, 西部黄金, 南宁百货, 富邦股份   \n",
       "...                                                   ...   \n",
       "473680       东旭光电, 中国船舶, 飞龙股份, 东风汽车, 福田汽车, 百奥泰, 宝泰隆, 仕佳光子   \n",
       "473681  东北证券, 智飞生物, 五粮液, 史丹利, 中信建投, 国泰君安, 中金公司, 长江证券, ...   \n",
       "473682  中国核电, 东北证券, 恒生电子, 浙商证券, 中信建投, 迈瑞医疗, 国泰君安, 中金公司...   \n",
       "473683                                         药明康德, 海尔生物   \n",
       "473684  宁德时代, 亿纬锂能, 胜利精密, 中兴通讯, 平安银行, 文科园林, 天赐材料, 云南白药...   \n",
       "\n",
       "                                Implicit_Negative_Company  \n",
       "0       航天信息, 怡亚通, 工商银行, 聚龙股份, 平安银行, 晨鸣纸业, 中金公司, 民生银行,...  \n",
       "1                                                    ST云维  \n",
       "2                                                    None  \n",
       "3                                                    None  \n",
       "4                                                    None  \n",
       "...                                                   ...  \n",
       "473680                                               None  \n",
       "473681                                         华谊嘉信, 西水股份  \n",
       "473682                                   三特索道, 中源家居, 吉翔股份  \n",
       "473683                                               None  \n",
       "473684                                               None  \n",
       "\n",
       "[473685 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
