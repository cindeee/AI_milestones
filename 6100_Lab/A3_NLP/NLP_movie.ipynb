{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0fecaab9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import sys\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(0)"
      ],
      "id": "0fecaab9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4746bef1"
      },
      "source": [
        "## Movie Review Classifier üçøüìΩÔ∏è"
      ],
      "id": "4746bef1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c58cd71"
      },
      "source": [
        "In this assignment, we'll be training a model to classify movie reviews as 'good' or 'bad.'\\\n",
        "The data consists of 40,000 real move reviews from IMBD.\\\n"
      ],
      "id": "9c58cd71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ba6bc9b"
      },
      "source": [
        "We'll load the data as a zipped csv.¬†\\\n",
        "Notice that `pd.read_csv()` can take a URL as the path argument and that we can read in a compressed file without first expanding it if we specify the `compression` format!"
      ],
      "id": "3ba6bc9b"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65d14744",
        "outputId": "06d6dc11-1628-4119-f475-8a3f4af1164a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "directory_path = '/content/drive/My Drive/DCAI_lab/Lab-A3'\n",
        "os.chdir(directory_path)\n",
        "\n",
        "data_url = './data/movie_reviews.zip'\n",
        "df = pd.read_csv(data_url, compression='zip')"
      ],
      "id": "65d14744"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "29fd2bbd",
        "outputId": "bfdc0cc7-7534-4211-fcb6-8f3e980a4578"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  If you haven't seen this movie than you need t...      1\n",
              "1  but \"Cinderella\" gets my vote, not only for th...      0\n",
              "2  This movie is pretty cheesy, but I do give it ...      1\n",
              "3  I have not seen a Van Damme flick for a while,...      1\n",
              "4  This is a 'sleeper'. It defines Nicholas Cage....      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48e81035-3c93-49ec-96c4-1cb305779d6c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>If you haven't seen this movie than you need t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>but \"Cinderella\" gets my vote, not only for th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This movie is pretty cheesy, but I do give it ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have not seen a Van Damme flick for a while,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is a 'sleeper'. It defines Nicholas Cage....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48e81035-3c93-49ec-96c4-1cb305779d6c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48e81035-3c93-49ec-96c4-1cb305779d6c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48e81035-3c93-49ec-96c4-1cb305779d6c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8c5d689b-4f85-4abc-8290-190304560cbd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c5d689b-4f85-4abc-8290-190304560cbd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8c5d689b-4f85-4abc-8290-190304560cbd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.head()"
      ],
      "id": "29fd2bbd"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb303695",
        "outputId": "2502ea6d-4c40-4652-9faf-c5437cc2514e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.shape"
      ],
      "id": "cb303695"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fae19e0",
        "outputId": "f31e07ac-ed29-48e6-d32c-8805ea60f19e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df.label.unique()"
      ],
      "id": "3fae19e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8de24367"
      },
      "source": [
        "We see that the dataset consists of text reviews and binary labels. Intuitively, the positive class is \"good\" while the negative is \"bad.\""
      ],
      "id": "8de24367"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e51a555"
      },
      "source": [
        "Here are two examples from the dataset:"
      ],
      "id": "7e51a555"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "14999480",
        "outputId": "be3c93ea-1d43-4df3-eba9-792bb58fe2ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"If you haven't seen this movie than you need to. It rocks and you have to watch it. It is so funny and will make you laugh your guts out!! so you have to watch it and i saw it about a billion and a half times and still think it is funny. so you have to. yes i have memorized the whole movie and could quote it to you from start to finish. you must see this move. it is also cute because it is half a chick flick. if you don't watch it then you are really missing out.this movie even has cute guys in it and that is always a bonus. so in summary watch the movie now and trust me you will not be making a mistake. did i mention the music is good too. So you should like it if you enjoy music. This is a movie that they rated correctly and it will work for anyone.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'label: good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'but \"Cinderella\" gets my vote, not only for the worst of Disney\\'s princess movies, but for the worst movie the company made during Walt\\'s lifetime. The music is genuinely pretty, and the story deserves to be called \"classic.\" What fails in this movie are the characters, particularly the title character, who could only be called \"the heroine\" in the loosest sense of the term.<br /><br />After a brief prologue, the audience is introduced to Cinderella. She is waking up in the morning and singing \"A Dream is A wish Your Heart Makes.\" This establishes her as an idealist (and thus deserving of our sympathy). Unfortunately, the script gives us no clue as to what she is dreaming about. Freedom from her servant role? The respect of her step-family? Someone to talk to besides mice and birds? In one song (cut from the movie but presented in the special features section of the latest DVD) Cinderella relates her wish that there could be many of her so she could do her work more efficiently. You go girlfriend! In short, Cinderella is a very bland character. She passively accepts her step-family\\'s abuse, escaping into her unspoken dreams for relief. She only asserts herself once by reminding her stepmother that she is still a member of the family. For this, she is given permission to go the ball if she completes her housework and finds something to wear, a token gesture that is clearly absurd to everyone except, of course, Cinderella. Can anyone see Belle or Jasmine being such a doormat? If Cinderella is dull, her male counterpart is nothing short of lifeless. The Prince in Cinderella gets no dialog and almost no screen time. We are given no indication if he is a good man, if he respects Cinderella or anything. All we know is 1) he is a prince and 2) he dances well. Heck, even the prince from \"Snow White\" got to sing a romantic song at least. Not only does this lack of development make the romance less interesting, it makes Cinderella look like either a social climber or an idiot, weakening her already tenuous appeal.<br /><br />Perhaps realizing how dull the main characters were, the animators chose to give excessive screen time to the movie\\'s comic relief, Cinderella\\'s friends, the mice. Granted, these characters are amusing. Even so, when the comic relief steals the show from the principals, well, let\\'s just say your story has some problems.<br /><br />Dinsey loves to proclaim all its animated features as \"masterpieces.\" While many of them are, there are some that do not deserve this appellate in any way. Cinderella is a prime example of this fact.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'label: bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "labels = {0: 'bad', 1: 'good'}\n",
        "seen = {'bad': False, 'good': False}\n",
        "for i in range(df.shape[0]):\n",
        "    label = df.loc[i,'label']\n",
        "    if not seen[labels[label]]:\n",
        "        # display/print combination used to appease Ed's strange output behavior\n",
        "        display(df.loc[i, 'text'])\n",
        "        print()\n",
        "        display(f\"label: {labels[label]}\")\n",
        "        print()\n",
        "        seen[labels[label]] = True\n",
        "    if all(val == True for val in seen.values()):\n",
        "        break"
      ],
      "id": "14999480"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ee4ceb"
      },
      "source": [
        "**Some Preprocessing**"
      ],
      "id": "c1ee4ceb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9326a9b"
      },
      "source": [
        "In the 2nd example, we can see some html tags inside the review text.\n",
        "\n",
        "Complete the `remove_br()` function by providing its call to `re.sub()` with a regex that removes those pesky \"\\<br />\" tags from an input string, `x`.\\\n",
        "Speciffically, we should replace 2 consecutive occurances of \"\\<br />\" with a single space (can you see why?).\n",
        "\n",
        "**Hint:** It is good practice to use 'raw' string when writing regular expressions to ensure that special characters are treated correctly. Raw strings are appended with an 'r' like this: `r'this is a raw string'`"
      ],
      "id": "c9326a9b"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5b94fbca"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# fill in the regular expression\n",
        "# Define the regular expression to match two consecutive \"<br />\" tags and replace them with a space.\n",
        "remove_br = lambda x: re.sub(r'<br\\s*/>\\s*<br\\s*/>', ' ', x)\n"
      ],
      "id": "5b94fbca"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ff4edfe"
      },
      "source": [
        "Use the dataframe's `apply()` method to apply `remove_br` to each review in both train and test."
      ],
      "id": "2ff4edfe"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fb9893c2"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# Apply the function on the 'text' column of the dataframe\n",
        "df['text'] = df['text'].apply(remove_br)"
      ],
      "id": "fb9893c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05013853"
      },
      "source": [
        "And we can see that the tags have been removed!"
      ],
      "id": "05013853"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "30134871",
        "outputId": "0c81cfc9-684f-41a3-9322-a9e672f771ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This is a 'sleeper'. It defines Nicholas Cage. The plot is intricate and totally absorbing. The ending will blow you away. See it whenever you have the opportunity.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.loc[4,'text']"
      ],
      "id": "30134871"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57e4770d"
      },
      "source": [
        "Don't worry about any newline characters or backslashes you may see before apostrophes in the examples above. This is just a quirk of how Jupyter displays strings by default.\\\n",
        "We don't see that these characters if we explicitly `print` the string."
      ],
      "id": "57e4770d"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77fe245e",
        "outputId": "95bd65d8-a219-428b-e3d4-6db5965dabd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a 'sleeper'. It defines Nicholas Cage. The plot is intricate and totally absorbing. The ending will blow you away. See it whenever you have the opportunity.\n"
          ]
        }
      ],
      "source": [
        "example_str = df.loc[4,'text']\n",
        "print(example_str)"
      ],
      "id": "77fe245e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e105db9"
      },
      "source": [
        "We'll continue our preprocessing by next **removing punctuation**.\\\n",
        "But first, let's keep a copy of the data *with* punctuation. This will be useful at the end of the notebook when we want to display the original text of specific observations."
      ],
      "id": "1e105db9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5M76ZPx7YUl"
      },
      "source": [
        "**‚úçÔ∏èFurther preprocessing**\n",
        "\n",
        "Before removing punctuations, we further process the data, which includes:\n",
        "1. expanding english contractoins (don't --> do not)\n",
        "2. removing URLs\n",
        "\n",
        "- here we do not remove all the numbers#, since they can give a strong indicator on sentiment anlysis. (7/10 --> positive)\n",
        "- these are also done for the preprocessing of test set.\n"
      ],
      "id": "u5M76ZPx7YUl"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQNDyge-F-a2",
        "outputId": "e555af0e-3289-42bd-fcb3-e1fe520852ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "#before that, I chose to expand the english contractions\n",
        "!pip install contractions\n",
        "import contractions\n",
        "\n",
        "# Function to expand contractions in a given text\n",
        "def expand_contractions(text):\n",
        "    expanded_text = contractions.fix(text)\n",
        "    return expanded_text\n",
        "\n",
        "# Apply the expand_contractions function to the 'text' column in your DataFrame\n",
        "df['text'] = df['text'].apply(expand_contractions)\n"
      ],
      "id": "ZQNDyge-F-a2"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB8GW24gCTdp",
        "outputId": "5cd56072-ab33-46f8-974a-98089390561f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total URLs found: 94\n"
          ]
        }
      ],
      "source": [
        "# to remove urls\n",
        "import re\n",
        "\n",
        "pattern = r\"http[s]?://\\S+\"\n",
        "\n",
        "# Initialize a counter\n",
        "url_count = 0\n",
        "# Iterate through the 'text' column in your DataFrame\n",
        "for text in df['text']:\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        # Increment the counter if a URL is found\n",
        "        url_count += 1\n",
        "# Print the total count of URLs found in the DataFrame\n",
        "print(f\"Total URLs found: {url_count}\")\n",
        "\n",
        "# Function to remove URLs from a given text\n",
        "def remove_urls(text):\n",
        "    return re.sub(pattern, '', text)\n",
        "\n",
        "# Apply the remove_urls function to the 'text' column in your DataFrame\n",
        "df['text'] = df['text'].apply(remove_urls)\n"
      ],
      "id": "HB8GW24gCTdp"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "63e3b9d6"
      },
      "outputs": [],
      "source": [
        "# store copy of data with punctuation\n",
        "df_raw = df.copy()"
      ],
      "id": "63e3b9d6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73aa28d4"
      },
      "source": [
        "The next regex we need is a bit more involved.\\\n",
        "**This should match any non-whitespace, any non-alphanumeric characters, and underscores** (strangly, underscores are not covered by the first 2 conditions).\n",
        "\n",
        "**Hints:**\n",
        "- `\\w` matches alphanumeric characters\n",
        "- `\\s` matches whitespace\n",
        "- `[]` can be used to denote a set of characters. ex: `r'[ab]'` will match on 'a' *or* 'b'\n",
        "- `^` at the beginning of a character set denotes *negation*. ex: `r'[^0-9]'` will matching any non-integer\n",
        "- `|` is the *logical or* operator. ex: `r'cat|dog'` will match the strings 'cat' *or* 'dog'\n",
        "- There are many helpful sites for testing regexes. [Here's a nice one](https://www.regextester.com/)."
      ],
      "id": "73aa28d4"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1c714b28"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# create a regex that will match the characters described above\n",
        "punc_regex =  r'[^\\w\\s]|_'"
      ],
      "id": "1c714b28"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09b57e39"
      },
      "source": [
        "Here we'll use an alternative to the `apply` approach we saw above.\\\n",
        "Pandas has its own set of built-in string methods which includes a version of `replace`. But unlike Python's `str.replace()` this can actually use regexes!"
      ],
      "id": "09b57e39"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8a874d3f"
      },
      "outputs": [],
      "source": [
        "df['text'] = df.text.str.replace(punc_regex, '', regex=True) # remove punctuation"
      ],
      "id": "8a874d3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "562cbd2e"
      },
      "source": [
        "If all went well we can see that punctuation has been removed from our dataset."
      ],
      "id": "562cbd2e"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a82b9bcb",
        "outputId": "018e5db9-5e0d-4020-c0b0-d3bf5a807898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This movie has no heart and no soul its an attempt to whomp up a cult film out of the leavings of other better directors principally David Lynch and Tim Burton Rifkin seems to think that if he overloads on a kind of rotted visual style and fills the street with crud and garbage hes making a statement But its not a statement ABOUT anything  except the directors shrill shriek of HEY LOOK AT ME IM AN ARTIST TOO But he doesnt have the imagination of an artist just a good memory for things that worked  such as some of the actors trapped in this  for other directors All of this would be almost acceptable if this movie was not a turgid boring chore to sit through\n"
          ]
        }
      ],
      "source": [
        "example_str = df.loc[5,'text']\n",
        "print(example_str)"
      ],
      "id": "a82b9bcb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we also add lemmatisation to reduce words to base form as a single term."
      ],
      "metadata": {
        "id": "u3T-9cAYbHoi"
      },
      "id": "u3T-9cAYbHoi"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id-x1KnwbEdU",
        "outputId": "5c164a0d-89d2-46f5-ec79-63ad367dfab7"
      },
      "id": "id-x1KnwbEdU",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define function to lemmatize text\n",
        "def lemmatize_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Apply lemmatization to 'text' column\n",
        "df['text'] = df['text'].apply(lemmatize_text)"
      ],
      "metadata": {
        "id": "YmhaBzgzbYIY"
      },
      "id": "YmhaBzgzbYIY",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23d4105"
      },
      "source": [
        "**Train/Test Split**\n",
        "\n",
        "Rather than splitting the data directly with `train_test_split` we'll instead use it to generate indices for the train and test data.\\\n",
        "This may seem strange, but there is a good reason for it. These indices will later allow us to recover the original, unprocessed text from `df_raw` for any given training and test observations.\n",
        "\n",
        "Notice too that we are stratifying on the label. This will help ensure that good and bad reviews appear in the same proportions in both train and test."
      ],
      "id": "d23d4105"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "41b691ae"
      },
      "outputs": [],
      "source": [
        "# generate indices to designate train and test observations\n",
        "train_idx, test_idx = train_test_split(range(df.shape[0]), test_size=0.15,\n",
        "                                       random_state=123, stratify=df['label'])"
      ],
      "id": "41b691ae"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "a22a946e"
      },
      "outputs": [],
      "source": [
        "# Separate the predictor from the response\n",
        "x = df.text.values\n",
        "y = df.label.values"
      ],
      "id": "a22a946e"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9e3d9de1"
      },
      "outputs": [],
      "source": [
        "# Create train and test sets using the generated indices\n",
        "x_train = x[train_idx]\n",
        "y_train = y[train_idx]\n",
        "x_test = x[test_idx]\n",
        "y_test = y[test_idx]"
      ],
      "id": "9e3d9de1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3886b9b5"
      },
      "source": [
        "**Building the Classifier Pipeline**\\\n",
        "**Step 1: Vectorizor**\n",
        "\n",
        "It's true that there are still several preprocessing steps to be done such as converting to lowercase and tokenizing the reviews, but these can be done for using sklearn's [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
      ],
      "id": "3886b9b5"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrrqllUHqdWr",
        "outputId": "c58dd0e6-7f26-4e1b-f824-c45836407438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, huggingface-hub, datasets\n",
            "Successfully installed datasets-2.14.6 dill-0.3.7 huggingface-hub-0.19.0 multiprocess-0.70.15\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "from datasets import Dataset"
      ],
      "id": "yrrqllUHqdWr"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1d88b818"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "id": "1d88b818"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df712db2"
      },
      "source": [
        "Instantiate a `TfidfVectorizer` with parameters such that it will:\n",
        "- set all reviews to lowercase\n",
        "- remove english stopwords\n",
        "- exclude words that occur in less than 1 review in 10,000\n",
        "- exclude words that occur in more than 90% of reviews\n",
        "\n",
        "**Hint:** Reading the documentation, you'll see the arguments you need are `lowercase`, `stop_words`, `min_df`, and `max_df`"
      ],
      "id": "df712db2"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2e236cc8"
      },
      "outputs": [],
      "source": [
        "# please fill this code block\n",
        "vec = TfidfVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 3),\n",
        "                      min_df=0.0001, max_df=0.9, max_features = 60000)"
      ],
      "id": "2e236cc8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a24c836"
      },
      "source": [
        "**Step 2: Classifier**\n",
        "\n",
        "We'll use logistic regression with l2 regularization as our classifier model. The [LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html?highlight=logisticregressioncv#sklearn.linear_model.LogisticRegressionCV) object allows us to easily tune for the best regularization parameter."
      ],
      "id": "0a24c836"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "078f881f"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV"
      ],
      "id": "078f881f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97f66e5e"
      },
      "source": [
        "With 40,000 training observations and each word in the vectorizer's vocabulary counting acting as a predictor training could be slow.\\\n",
        "This issue is exacerbated when using cross validation as we need fit the model multiple times!\\\n",
        "We'll set our classifier CV parameters so as to help keep the training time down to around 30 seconds or so.\n",
        "- l2 penalty (e.g., Ridge)\n",
        "- 10 iterations per fit (remember, logistic regression has no closed form solution for the betas!)\n",
        "- 5-fold CV\n",
        "- random state of 0 (the fitting can be stochastic)"
      ],
      "id": "97f66e5e"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "317752aa"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# Instantiate our Classifier\n",
        "clf = LogisticRegressionCV(penalty='l2', max_iter=20, cv=5, random_state=888)"
      ],
      "id": "317752aa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ef7e1f"
      },
      "source": [
        "**Step 3: Pipeline**\n",
        "\n",
        "Any text data going into our classifier will have to first be converted to numerical data by our vectorizer.\\\n",
        "One way to do this would be to:\n",
        "1. fit the vectorizor on the training data\n",
        "2. transform a dataset with the fitted vectorizer\n",
        "3. pass the transformed data to the classifier\n",
        "\n",
        "(1) only needs to be done once, but (2) & (3) would need to be done manually for train, test, and any other data we want to give them model.\\\n",
        "This would be tedious! Luckily, sklearn's [Pipline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html?highlight=pipeline#sklearn.pipeline.Pipeline) object allow use to connect one more 'transformers' (such as a scaler or vectorizer) with a model."
      ],
      "id": "90ef7e1f"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "c7897ac0"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline"
      ],
      "id": "c7897ac0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15be90c9"
      },
      "source": [
        "Use [make_pipeline()](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=make_pipeline#sklearn.pipeline.make_pipeline) to connect the vectorizor, `vec`, and our classifier, `clf`, into a single pipeline.\n",
        "\n",
        "**Hint:** You can set `verbose=True` to see the individual steps during the fit process later."
      ],
      "id": "15be90c9"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9f7a47d1"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# Construct the pipeline\n",
        "pipe = make_pipeline( vec, clf, verbose=True)"
      ],
      "id": "9f7a47d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20fe0b5d"
      },
      "source": [
        "**Step 4: Fitting**\n",
        "\n",
        "When it comes to fitting, we can treat the pipeline object as if it were the classifier object itself, and simply call `fit` on the pipeline."
      ],
      "id": "20fe0b5d"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "32a3d208"
      },
      "outputs": [],
      "source": [
        "# For the sake of time, we are fitting quickly and we may not converge\n",
        "# We'll supress those pesky warnings\n",
        "from warnings import simplefilter\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "# We also ignore FutureWarnings due to version issues on Ed\n",
        "simplefilter(\"ignore\", category=(ConvergenceWarning, FutureWarning))"
      ],
      "id": "32a3d208"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE1ZRPpBsUt7"
      },
      "outputs": [],
      "source": [
        "pipe.fit(x_train, y_train)"
      ],
      "id": "hE1ZRPpBsUt7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5e449d2"
      },
      "source": [
        "We can inspect the steps of the pipeline."
      ],
      "id": "b5e449d2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feb94be9"
      },
      "outputs": [],
      "source": [
        "pipe.get_params()['steps']"
      ],
      "id": "feb94be9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41580761"
      },
      "source": [
        "By default they are named using the all lowercase class name of each object.\\\n",
        "We can use these names to access the fitted objects inside. Here we see the size of our vectorizer's vocabulary."
      ],
      "id": "41580761"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccca2cec",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "features = pipe.get_params()['tfidfvectorizer'].get_feature_names_out()\n",
        "print('# of features:', len(features))"
      ],
      "id": "ccca2cec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8706fcf1"
      },
      "source": [
        "There are too many to print, but we can peek at a random sample."
      ],
      "id": "8706fcf1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "929a8397"
      },
      "outputs": [],
      "source": [
        "sample_size = 40\n",
        "feature_sample_idx = np.random.choice(len(features), size=sample_size, replace=False)\n",
        "print(np.array(features)[feature_sample_idx])"
      ],
      "id": "929a8397"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97f3f2e8"
      },
      "source": [
        "Similarly, we can access the fitted logistic model and see what regularization parameter was used."
      ],
      "id": "97f3f2e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86399e47",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "best_C = pipe.get_params()['logisticregressioncv'].C_[0]\n",
        "print(f'Best C from cross-validation: {best_C:.4f}')"
      ],
      "id": "86399e47"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cab190d"
      },
      "source": [
        "**Step 5: Prediction**\n",
        "\n",
        "Just like we did when fitting, we can treat the pipeline object as the classifier when making predictions.\\\n",
        "Predict on the test data to get:\n",
        "1. class labels\n",
        "2. probabilities of being the positive class (i.e., 'good' reviews)\n",
        "3. test accuracy"
      ],
      "id": "0cab190d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b0d084b"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# Predict class labels on test data\n",
        "y_pred = pipe.predict(x_test)\n",
        "\n",
        "# Predict probabilities of the positive on the test data\n",
        "y_pred_proba = pipe.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# Calculate test accuracy (there are several ways to do this)\n",
        "from sklearn.metrics import accuracy_score\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"test accuracy: {test_acc:0.3f}\")"
      ],
      "id": "0b0d084b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ae3f289"
      },
      "source": [
        "Can you get better than 0.893 by tweaking the preprocessing, or vetorizer and classifier parameters? Perhaps inspecting how our model makes its predictions may help us decide how we might improve the model in the future."
      ],
      "id": "0ae3f289"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ccc9200"
      },
      "source": [
        "### Kaggle Submission Process for Movie Review Classification\n",
        "\n",
        "In the subsequent steps, we'll process the test dataset provided on Kaggle, produce a predicted output, and generate a CSV file suitable for submission. This will allow us to evaluate our model's predictions on Kaggle. Access the competition through this [link](https://www.kaggle.com/competitions/dsaa-6100-movie-review-classification/): **DSAA 6100 Movie Review Classification**.\n",
        "\n",
        "When participating in the competition on Kaggle, please ensure your displayed username follows the format \"StudentID_Name\". This will help the teaching assistants to easily identify and verify your scores. For instance, change your Kaggle display name to a format similar to \"50013772_Yupeng Xie\" before submitting."
      ],
      "id": "3ccc9200"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vcEemAMU1F5"
      },
      "outputs": [],
      "source": [
        "# 1. Load the 'test_data.csv' file\n",
        "test_data = pd.read_csv('data/test_data.csv')\n"
      ],
      "id": "8vcEemAMU1F5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ee8aecd"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "test_data['text'] = test_data['text'].apply(remove_br)\n",
        "test_data['text'] = test_data['text'].apply(expand_contractions)\n",
        "test_data['text'] = test_data['text'].apply(remove_urls)\n",
        "test_data['text'] = test_data.text.str.replace(punc_regex, '', regex=True)\n",
        "# Extract reviews from 'test_data.csv' assuming the column name is \"text\"\n",
        "test_reviews = test_data['text']\n"
      ],
      "id": "1ee8aecd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_uaW_v8SWu8",
        "outputId": "18f684b8-9669-4b71-86b8-53dba9c86e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle submission file saved as 'kaggle_submission.csv'\n"
          ]
        }
      ],
      "source": [
        "# 2. Predict sentiments using the trained model\n",
        "y_pred_kaggle = pipe.predict(test_reviews)\n",
        "\n",
        "# 3. Create a dataframe for Kaggle submission\n",
        "# Assuming 'test_data' has a column named 'Id' for identifying each review\n",
        "submission = pd.DataFrame({'Id': test_data['Id'], 'Category': y_pred_kaggle})\n",
        "\n",
        "# 4. Save the predictions to a .csv file for submission\n",
        "submission.to_csv('kaggle_submission.csv', index=False)\n",
        "\n",
        "print(\"Kaggle submission file saved as 'kaggle_submission.csv'\")"
      ],
      "id": "n_uaW_v8SWu8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea0203db"
      },
      "source": [
        "### Interpretation\n",
        "\n",
        "Below we'll use the `eli5` library to have some fun interpreting what is driving our model's predictions on specific test observations.\n",
        "\n",
        "- [ELI5](https://eli5.readthedocs.io/en/latest/) is a Python library which allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides a way to explain black-box models."
      ],
      "id": "ea0203db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c65b9d8c",
        "outputId": "39a05f3e-52c0-4426-ae2f-0c3f33069bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eli5\n",
            "  Downloading eli5-0.13.0.tar.gz (216 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.2/216.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>17.1.0 in /usr/local/lib/python3.10/dist-packages (from eli5) (23.1.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from eli5) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from eli5) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from eli5) (1.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from eli5) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from eli5) (1.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from eli5) (0.20.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from eli5) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.0->eli5) (2.1.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->eli5) (3.2.0)\n",
            "Building wheels for collected packages: eli5\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eli5: filename=eli5-0.13.0-py2.py3-none-any.whl size=107719 sha256=c7ffa7d2706e81b7653dd4b3f1f7b4aca188fc846f4adde5d0429d0e8aa82e4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/58/ef/2cf4c306898c2338d51540e0922c8e0d6028e07007085c0004\n",
            "Successfully built eli5\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.13.0\n"
          ]
        }
      ],
      "source": [
        "# please fill this code block!\n",
        "# Install ELI5\n",
        "!pip install eli5\n"
      ],
      "id": "c65b9d8c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb097024"
      },
      "outputs": [],
      "source": [
        "# For interpretation\n",
        "import eli5\n",
        "# for parsing/formating eli5's HTML output\n",
        "from bs4 import BeautifulSoup\n",
        "# for displaying formatted HTML output\n",
        "from IPython.display import HTML"
      ],
      "id": "fb097024"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf8566b4"
      },
      "source": [
        "Here are the words driving positive class predictions."
      ],
      "id": "bf8566b4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "303414ee",
        "outputId": "73c67314-3f3a-495e-bee2-fa4032ee21e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 84.16%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +15.223\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        excellent\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 84.31%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +15.007\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        710\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.24%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +13.762\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        great\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.60%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +11.981\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        wonderful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.96%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +11.521\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        perfect\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.05%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +11.412\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        best\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.55%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +10.788\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        amazing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.11%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +10.099\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        hilarious\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.13%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +10.076\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        loved\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.13%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 68088 more positive &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.11%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 66907 more negative &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.11%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -10.096\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        supposed\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.96%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -10.278\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        lame\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.68%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -10.628\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        poorly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.61%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -10.709\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        fails\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.20%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -11.228\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        terrible\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.06%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -11.395\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        poor\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.81%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -11.715\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        worse\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.79%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -11.745\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        horrible\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.76%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -11.775\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        dull\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.58%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -12.007\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointment\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.31%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -12.360\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        410\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.31%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -15.009\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        boring\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.20%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -15.163\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        bad\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 83.65%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -15.917\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        waste\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 82.98%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -16.868\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        awful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -21.234\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        worst\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_names = vec.get_feature_names_out()\n",
        "eli5.show_weights(clf, vec=vec, feature_names=feature_names, top=25)"
      ],
      "id": "303414ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bec2b7a"
      },
      "source": [
        "Hmm, those digits like 710, 810, and 410 driving predictions seems strange. What might they represent?\\"
      ],
      "id": "9bec2b7a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5c0d164"
      },
      "source": [
        "We'll use the 'raw' data with punctuation when inspecting the data (See! It is coming in handy!)"
      ],
      "id": "a5c0d164"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3289273b"
      },
      "outputs": [],
      "source": [
        "x_train_raw = df_raw.text[train_idx].values\n",
        "x_test_raw = df_raw.text[test_idx].values"
      ],
      "id": "3289273b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "08afdf62",
        "outputId": "cb2a1033-f613-41b8-e10f-916b09456e76"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I have seen a lot of PPV's in the past but this is the most entertaining, intense PPV and the most complete DVD i have ever seen. The DVD extras are worth it because they it gives a different view of how the wrestlers act after the show (such as the chris benoit interview/edge interview), some glimpse into the Monday Night Wars era,the first match of Hogan winning tag title gold and some promotional talk. Additionally there is a good music video. 1. Tag Team Table match: Bubby Ray and Spike Dudley vs. Eddie Guerro and Chris benoit 7/10 This was a pretty good intense match to start off the show. Not too many holds and just pure raw physicallity. Spike can hold his own in tables matches and Guerro and Benoit gave good pure wrestling skills on the mat.  2. WWE Crusierweight championship: Jamie Noble w/ Nidia v. Billy Kidman 3/10 The crowd really did not care about either wrestler and did not get interested until Kidman did a shooting star press. Usually people expect a lot of high flying in a cruiser weight championship, but this had very little. In fact it was so bad that when Noble hit his finisher, no one even cared or knew (you can tell by the lack of camera's flashing). The ending was quick though.  3. WWE European Championship: Jeff hardy v. William Regal 5/10 I have never really liked regal as a wrestler, he lacks intensity and style. Hardy was impressive but really did not get a chance to show off his high flying act, although he still performed some good counters and added that needed fast pace to the match. It ended off quickly which was perfect for this match.  4. John Cena v. Chris Jericho 6/10 It is funny looking back at Cena's very first PPV, how he used to act, how he used to dress, and how he used to look (watch his interview, it is pretty funny). This was a good intense match with Cena showing a nice variety of holds, suplexes, counters and some aerial. Jericho was sub-par but definitely helped Cena launch his career. Cena Wins. 5. WWE Intercontenital championship: RVD v. Brock Lesnar 8/10 This was a very intense and good match. Both wrestlers styles really matched up well on the screen, with Brocks pure power and raw energy vs. RVDs skill full moves and quickness. RVD looked great in this match (better than his later matches with edge and cena)and the entire match was fast pace. The ending worked perfectly because it still preserved Brock's undefeated streak while giving RVD his just desserts in his home state. 6. No disqualification match: Booker T v. Big Show 7/10 Another solid match that lacked a certain intensity as the RVD match but still a good follow up. Although it started off kind of slow (which it always is with big show) Booker T was impressive and did a sick move on the announcers table. The finisher was awesome, the ending was a great upset and big move up for Booker T. 7. WWE Tag Team Championship: Hogan and Edge v. Christian and Lance storm 5/10 This was a mediocre match. Hogan comes out like usual to a huge pop but his variety of moves lacks that intensity and energy. Then again Christian does not exactly have the greatest athletic abilities himself. This ended up being a mediocre match at best but was still OK for PPV.  8. Triple Threat Match for the Undisputed Championship: 10/10. Rock v. Undertaker v. Kurt Angle. Easily the match of the year. This is by far the best triple threat match i have ever seen. It had close falls, plenty of finishers, stolen finishers, raw energy, intensity and fast pace. No one could predict who would come out of this one. If your going to buy this DVD i would buy it strictly for this match. (ending? watch for yourself!) Overall this was a solid PPV with plenty of extra goodies to keep you watching again and again. Although this is hard to find (i had to pay a little more than usual for this DVD) it is definitely worth your money.\""
            ]
          },
          "execution_count": 277,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw[df.text.str.contains(' 710 ')].iloc[0].text"
      ],
      "id": "08afdf62"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1cfea85"
      },
      "source": [
        "These are actually numerical ratings embedded in the reviews! Looking at the text without the punctuation made it hard for us to see this at first."
      ],
      "id": "a1cfea85"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3b2fcd6"
      },
      "source": [
        "Here's a helper function used to remove some extraneous things from `eli5`'s output. We just want to see the highlighted text.\\\n",
        "You don't need to read through the function but it is here as a nice resource/example. ü§ì"
      ],
      "id": "c3b2fcd6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eafdf41f"
      },
      "outputs": [],
      "source": [
        "def eli5_html(clf, vec, observation):\n",
        "    \"\"\"\n",
        "    helper function for nicely formatting and displaying eli5 output\n",
        "    \"\"\"\n",
        "    # Get info on is driving a given observation's predictions\n",
        "    eli5_results = eli5.show_prediction(estimator=clf, doc=observation,\n",
        "                                        vec=vec, targets=[True], target_names=['bad', 'good'],\n",
        "                                        feature_names=feature_names)\n",
        "    # Convert eli5's HTML data to BS object for parsing/formatting\n",
        "    soup = BeautifulSoup(eli5_results.data, 'html.parser')\n",
        "    # Remove a table we don't want\n",
        "    soup.table.decompose()\n",
        "    # Remove the first <p> tag with unwanted text\n",
        "    soup.p.decompose()\n",
        "    # Display the newly formatted HTML!\n",
        "    display(HTML(str(soup)))"
      ],
      "id": "eafdf41f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a026c04a"
      },
      "source": [
        "Now all you need to do is find the specific observations requested.\\\n",
        "You'll need your `y_pred_proba` values for this section to find which elements from `x_test_raw` to select.\n",
        "\n",
        "**Hint:** [np.argsort()](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html), [np.flip()](https://numpy.org/doc/stable/reference/generated/numpy.flip.html?highlight=flip#numpy.flip), and [np.abs()](https://numpy.org/doc/stable/reference/generated/numpy.absolute.html) may be useful here."
      ],
      "id": "a026c04a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fffa9cf"
      },
      "source": [
        "### What are the **5 worst** movie reviews in the test set according to your model? üçÖ"
      ],
      "id": "0fffa9cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d18f27e"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# Find indices of 5 worst reviews\n",
        "worst5 = x_test_raw[np.argsort(np.abs(y_pred_proba))[:5]]"
      ],
      "id": "8d18f27e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1130af96",
        "outputId": "88f88cf0-b546-48c0-a3cb-544cc7a12c40"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p style=background-color:black;color:white;font-weight:bold;padding:4px>Bad Movie #1 üçÖ</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "<p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "<span style=\"opacity: 0.80\">as you can </span><span style=\"background-color: hsl(0, 100.00%, 98.63%); opacity: 0.80\" title=\"-0.008\">tell</span><span style=\"opacity: 0.80\"> from the other </span><span style=\"background-color: hsl(120, 100.00%, 91.27%); opacity: 0.82\" title=\"0.115\">comments</span><span style=\"opacity: 0.80\">, this </span><span style=\"background-color: hsl(0, 100.00%, 89.90%); opacity: 0.83\" title=\"-0.142\">movie</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 86.49%); opacity: 0.84\" title=\"-0.215\">just</span><span style=\"opacity: 0.80\"> about the </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.014\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.12%); opacity: 0.85\" title=\"-0.247\">film</span><span style=\"opacity: 0.80\"> ever made. </span><span style=\"background-color: hsl(0, 100.00%, 91.66%); opacity: 0.82\" title=\"-0.108\">let</span><span style=\"opacity: 0.80\"> me see how many </span><span style=\"background-color: hsl(120, 100.00%, 86.51%); opacity: 0.84\" title=\"0.215\">different</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.62%); opacity: 0.81\" title=\"0.058\">words</span><span style=\"opacity: 0.80\"> i can </span><span style=\"background-color: hsl(0, 100.00%, 95.40%); opacity: 0.81\" title=\"-0.046\">use</span><span style=\"opacity: 0.80\"> to describe it: </span><span style=\"background-color: hsl(0, 100.00%, 69.31%); opacity: 0.94\" title=\"-0.695\">boring</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 83.11%); opacity: 0.86\" title=\"-0.296\">unbearable</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 75.28%); opacity: 0.90\" title=\"-0.510\">laughable</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 79.17%); opacity: 0.88\" title=\"-0.399\">lousy</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 79.56%); opacity: 0.88\" title=\"-0.389\">stupid</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 72.49%); opacity: 0.92\" title=\"-0.594\">horrible</span><span style=\"opacity: 0.80\">..... i could go on with such </span><span style=\"background-color: hsl(120, 100.00%, 94.81%); opacity: 0.81\" title=\"0.055\">descriptions</span><span style=\"opacity: 0.80\"> but you </span><span style=\"background-color: hsl(120, 100.00%, 98.20%); opacity: 0.80\" title=\"0.012\">probably</span><span style=\"opacity: 0.80\"> get the </span><span style=\"background-color: hsl(0, 100.00%, 87.41%); opacity: 0.84\" title=\"-0.194\">point</span><span style=\"opacity: 0.80\">. i would have </span><span style=\"background-color: hsl(0, 100.00%, 91.59%); opacity: 0.82\" title=\"-0.109\">given</span><span style=\"opacity: 0.80\"> this a 0, if </span><span style=\"background-color: hsl(0, 100.00%, 91.28%); opacity: 0.82\" title=\"-0.115\">possible</span><span style=\"opacity: 0.80\">--</span><span style=\"background-color: hsl(0, 100.00%, 79.79%); opacity: 0.88\" title=\"-0.382\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.54%); opacity: 0.83\" title=\"-0.129\">acting</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 82.93%); opacity: 0.86\" title=\"-0.301\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.15%); opacity: 0.82\" title=\"-0.099\">directing</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 74.69%); opacity: 0.90\" title=\"-0.527\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.53%); opacity: 0.80\" title=\"-0.019\">production</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 74.28%); opacity: 0.91\" title=\"-0.540\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.58%); opacity: 0.85\" title=\"-0.236\">plot</span><span style=\"opacity: 0.80\">. this was made in </span><span style=\"background-color: hsl(120, 100.00%, 90.02%); opacity: 0.83\" title=\"0.140\">2001</span><span style=\"opacity: 0.80\"> and it </span><span style=\"background-color: hsl(0, 100.00%, 84.03%); opacity: 0.85\" title=\"-0.273\">looks</span><span style=\"opacity: 0.80\"> more </span><span style=\"background-color: hsl(0, 100.00%, 91.21%); opacity: 0.82\" title=\"-0.116\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.50%); opacity: 0.81\" title=\"-0.076\">1965</span><span style=\"opacity: 0.80\">. very </span><span style=\"background-color: hsl(0, 100.00%, 87.20%); opacity: 0.84\" title=\"-0.199\">low</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.62%); opacity: 0.81\" title=\"-0.058\">budget</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 69.51%); opacity: 0.94\" title=\"-0.688\">boring</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.48%); opacity: 0.83\" title=\"-0.150\">plot</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 69.59%); opacity: 0.94\" title=\"-0.686\">horrible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.68%); opacity: 0.87\" title=\"-0.332\">acting</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 85.81%); opacity: 0.85\" title=\"-0.231\">really</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.55%); opacity: 0.89\" title=\"-0.473\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.07%); opacity: 0.85\" title=\"0.248\">special</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.55%); opacity: 0.81\" title=\"0.075\">effects</span><span style=\"opacity: 0.80\">, etc... i </span><span style=\"background-color: hsl(120, 100.00%, 94.51%); opacity: 0.81\" title=\"0.059\">rarely</span><span style=\"opacity: 0.80\"> ever see a </span><span style=\"background-color: hsl(120, 100.00%, 95.32%); opacity: 0.81\" title=\"0.047\">sci</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 86.11%); opacity: 0.84\" title=\"0.224\">fi</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.45%); opacity: 0.80\" title=\"0.002\">film</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(0, 100.00%, 91.87%); opacity: 0.82\" title=\"-0.104\">absolutely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.01%); opacity: 0.80\" title=\"-0.014\">think</span><span style=\"opacity: 0.80\"> is this </span><span style=\"background-color: hsl(0, 100.00%, 74.57%); opacity: 0.90\" title=\"-0.531\">bad</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 91.54%); opacity: 0.82\" title=\"-0.110\">mean</span><span style=\"opacity: 0.80\"> this is </span><span style=\"background-color: hsl(120, 100.00%, 90.72%); opacity: 0.82\" title=\"0.126\">pure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.14%); opacity: 0.88\" title=\"-0.400\">garbage</span><span style=\"opacity: 0.80\">. it has nothing </span><span style=\"background-color: hsl(0, 100.00%, 99.84%); opacity: 0.80\" title=\"-0.000\">going</span><span style=\"opacity: 0.80\"> for it either. as </span><span style=\"background-color: hsl(0, 100.00%, 81.67%); opacity: 0.87\" title=\"-0.333\">far</span><span style=\"opacity: 0.80\"> as a \"b-</span><span style=\"background-color: hsl(120, 100.00%, 98.60%); opacity: 0.80\" title=\"0.008\">movie</span><span style=\"opacity: 0.80\">\" this is the very bottom of the </span><span style=\"background-color: hsl(120, 100.00%, 80.22%); opacity: 0.87\" title=\"0.371\">lot</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(120, 100.00%, 91.73%); opacity: 0.82\" title=\"0.107\">think</span><span style=\"opacity: 0.80\"> i would be more </span><span style=\"background-color: hsl(120, 100.00%, 95.76%); opacity: 0.81\" title=\"0.041\">entertained</span><span style=\"opacity: 0.80\"> by </span><span style=\"background-color: hsl(0, 100.00%, 97.27%); opacity: 0.80\" title=\"-0.022\">staring</span><span style=\"opacity: 0.80\"> at a </span><span style=\"background-color: hsl(0, 100.00%, 88.42%); opacity: 0.83\" title=\"-0.173\">blank</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.50%); opacity: 0.83\" title=\"-0.171\">piece</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 84.24%); opacity: 0.85\" title=\"-0.268\">paper</span><span style=\"opacity: 0.80\"> for </span><span style=\"background-color: hsl(0, 100.00%, 84.70%); opacity: 0.85\" title=\"-0.257\">90</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.42%); opacity: 0.87\" title=\"-0.339\">minutes</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 82.42%); opacity: 0.86\" title=\"-0.313\">junk</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.09%); opacity: 0.81\" title=\"-0.051\">like</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(120, 100.00%, 81.30%); opacity: 0.87\" title=\"0.342\">gives</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.94%); opacity: 0.84\" title=\"0.183\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.97%); opacity: 0.84\" title=\"-0.227\">low</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 94.32%); opacity: 0.81\" title=\"-0.062\">budget</span><span style=\"opacity: 0.80\"> \"b\" </span><span style=\"background-color: hsl(120, 100.00%, 93.82%); opacity: 0.81\" title=\"0.070\">movies</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 72.09%); opacity: 0.92\" title=\"-0.606\">bad</span><span style=\"opacity: 0.80\"> name. this </span><span style=\"background-color: hsl(120, 100.00%, 96.60%); opacity: 0.81\" title=\"0.030\">makes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.18%); opacity: 0.87\" title=\"-0.372\">ed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.67%); opacity: 0.85\" title=\"-0.258\">wood</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.01%); opacity: 0.81\" title=\"0.038\">movies</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.38%); opacity: 0.86\" title=\"-0.289\">look</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.14%); opacity: 0.86\" title=\"-0.295\">good</span><span style=\"opacity: 0.80\">. the </span><span style=\"background-color: hsl(0, 100.00%, 80.52%); opacity: 0.87\" title=\"-0.363\">thing</span><span style=\"opacity: 0.80\"> about </span><span style=\"background-color: hsl(0, 100.00%, 87.41%); opacity: 0.84\" title=\"-0.194\">watching</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.56%); opacity: 0.80\" title=\"-0.019\">direct</span><span style=\"opacity: 0.80\">-to-</span><span style=\"background-color: hsl(0, 100.00%, 93.30%); opacity: 0.82\" title=\"-0.079\">video</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.05%); opacity: 0.84\" title=\"-0.203\">movies</span><span style=\"opacity: 0.80\"> is, </span><span style=\"background-color: hsl(0, 100.00%, 89.32%); opacity: 0.83\" title=\"-0.154\">just</span><span style=\"opacity: 0.80\"> when you </span><span style=\"background-color: hsl(120, 100.00%, 91.17%); opacity: 0.82\" title=\"0.117\">think</span><span style=\"opacity: 0.80\"> you have </span><span style=\"background-color: hsl(0, 100.00%, 95.80%); opacity: 0.81\" title=\"-0.041\">seen</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 60.74%); opacity: 0.99\" title=\"-0.987\">worst</span><span style=\"opacity: 0.80\">, you see something even </span><span style=\"background-color: hsl(0, 100.00%, 73.41%); opacity: 0.91\" title=\"-0.566\">worse</span><span style=\"opacity: 0.80\">! </span><span style=\"background-color: hsl(120, 100.00%, 89.70%); opacity: 0.83\" title=\"0.146\">dj</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.10%); opacity: 0.80\" title=\"-0.013\">perry</span><span style=\"opacity: 0.80\"> is a </span><span style=\"background-color: hsl(0, 100.00%, 72.91%); opacity: 0.91\" title=\"-0.581\">horrible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.69%); opacity: 0.82\" title=\"-0.089\">actor</span><span style=\"opacity: 0.80\"> and has no </span><span style=\"background-color: hsl(120, 100.00%, 91.65%); opacity: 0.82\" title=\"0.108\">individual</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.64%); opacity: 0.81\" title=\"-0.057\">characteristics</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(0, 100.00%, 91.18%); opacity: 0.82\" title=\"-0.117\">make</span><span style=\"opacity: 0.80\"> him </span><span style=\"background-color: hsl(120, 100.00%, 95.46%); opacity: 0.81\" title=\"0.045\">stand</span><span style=\"opacity: 0.80\"> out. </span><span style=\"background-color: hsl(0, 100.00%, 77.83%); opacity: 0.89\" title=\"-0.437\">avoid</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(0, 100.00%, 66.95%); opacity: 0.95\" title=\"-0.772\">waste</span><span style=\"opacity: 0.80\"> at all </span><span style=\"background-color: hsl(0, 100.00%, 84.11%); opacity: 0.85\" title=\"-0.271\">costs</span><span style=\"opacity: 0.80\">! </span><span style=\"background-color: hsl(0, 100.00%, 82.69%); opacity: 0.86\" title=\"-0.306\">oh</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 88.42%); opacity: 0.83\" title=\"0.173\">humanity</span><span style=\"opacity: 0.80\">!</span>\n",
              "</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<p style=background-color:black;color:white;font-weight:bold;padding:4px>Bad Movie #2 üçÖ</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "<p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "<span style=\"background-color: hsl(0, 100.00%, 90.84%); opacity: 0.82\" title=\"-0.160\">ok</span><span style=\"opacity: 0.80\">, i </span><span style=\"background-color: hsl(120, 100.00%, 89.59%); opacity: 0.83\" title=\"0.192\">admit</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(120, 100.00%, 96.45%); opacity: 0.81\" title=\"0.041\">watched</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(0, 100.00%, 94.01%); opacity: 0.81\" title=\"-0.087\">movie</span><span style=\"opacity: 0.80\"> on </span><span style=\"background-color: hsl(0, 100.00%, 76.21%); opacity: 0.90\" title=\"-0.626\">mystery</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.31%); opacity: 0.94\" title=\"-0.901\">science</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.91%); opacity: 0.91\" title=\"-0.714\">theater</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.88%); opacity: 0.84\" title=\"-0.239\">3000</span><span style=\"opacity: 0.80\"> (which i am a </span><span style=\"background-color: hsl(0, 100.00%, 86.99%); opacity: 0.84\" title=\"-0.264\">huge</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.46%); opacity: 0.83\" title=\"-0.196\">fan</span><span style=\"opacity: 0.80\"> of), but i am not one of those </span><span style=\"background-color: hsl(120, 100.00%, 96.94%); opacity: 0.81\" title=\"0.033\">people</span><span style=\"opacity: 0.80\"> who </span><span style=\"background-color: hsl(0, 100.00%, 97.09%); opacity: 0.80\" title=\"-0.031\">automatically</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.37%); opacity: 0.83\" title=\"0.198\">gives</span><span style=\"opacity: 0.80\"> an </span><span style=\"background-color: hsl(0, 100.00%, 78.81%); opacity: 0.88\" title=\"-0.530\">mst3k</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.61%); opacity: 0.82\" title=\"0.118\">movie</span><span style=\"opacity: 0.80\"> a 1/</span><span style=\"background-color: hsl(120, 100.00%, 89.68%); opacity: 0.83\" title=\"0.190\">10</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.74%); opacity: 0.81\" title=\"0.054\">rating</span><span style=\"opacity: 0.80\">. although i </span><span style=\"background-color: hsl(120, 100.00%, 96.05%); opacity: 0.81\" title=\"0.048\">hate</span><span style=\"opacity: 0.80\"> many of the </span><span style=\"background-color: hsl(120, 100.00%, 95.24%); opacity: 0.81\" title=\"0.063\">movies</span><span style=\"opacity: 0.80\"> they </span><span style=\"background-color: hsl(120, 100.00%, 96.40%); opacity: 0.81\" title=\"0.042\">play</span><span style=\"opacity: 0.80\">, and some are among of the </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.315\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.27%); opacity: 0.85\" title=\"-0.316\">movies</span><span style=\"opacity: 0.80\"> i have ever </span><span style=\"background-color: hsl(0, 100.00%, 98.73%); opacity: 0.80\" title=\"-0.010\">seen</span><span style=\"opacity: 0.80\">, i have </span><span style=\"background-color: hsl(0, 100.00%, 92.04%); opacity: 0.82\" title=\"-0.131\">actually</span><span style=\"opacity: 0.80\"> been </span><span style=\"background-color: hsl(120, 100.00%, 94.41%); opacity: 0.81\" title=\"0.079\">able</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 88.37%); opacity: 0.83\" title=\"0.225\">enjoy</span><span style=\"opacity: 0.80\"> some </span><span style=\"background-color: hsl(0, 100.00%, 78.81%); opacity: 0.88\" title=\"-0.530\">mst3k</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.31%); opacity: 0.80\" title=\"-0.014\">movies</span><span style=\"opacity: 0.80\">. that being </span><span style=\"background-color: hsl(0, 100.00%, 98.72%); opacity: 0.80\" title=\"-0.010\">said</span><span style=\"opacity: 0.80\">, this is one of the </span><span style=\"background-color: hsl(0, 100.00%, 63.42%); opacity: 0.98\" title=\"-1.157\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.27%); opacity: 0.85\" title=\"-0.316\">movies</span><span style=\"opacity: 0.80\"> i have ever </span><span style=\"background-color: hsl(120, 100.00%, 96.66%); opacity: 0.81\" title=\"0.038\">seen</span><span style=\"opacity: 0.80\">. (it is no </span><span style=\"background-color: hsl(0, 100.00%, 86.39%); opacity: 0.84\" title=\"-0.282\">wonder</span><span style=\"opacity: 0.80\">, in </span><span style=\"background-color: hsl(0, 100.00%, 97.66%); opacity: 0.80\" title=\"-0.023\">fact</span><span style=\"opacity: 0.80\">, that the </span><span style=\"background-color: hsl(0, 100.00%, 78.81%); opacity: 0.88\" title=\"-0.530\">mst3k</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.09%); opacity: 0.84\" title=\"-0.261\">writers</span><span style=\"opacity: 0.80\"> themselves </span><span style=\"background-color: hsl(120, 100.00%, 93.74%); opacity: 0.81\" title=\"0.093\">commented</span><span style=\"opacity: 0.80\"> that this one was one of the </span><span style=\"background-color: hsl(0, 100.00%, 71.01%); opacity: 0.93\" title=\"-0.830\">worst</span><span style=\"opacity: 0.80\">. do not </span><span style=\"background-color: hsl(0, 100.00%, 92.27%); opacity: 0.82\" title=\"-0.126\">believe</span><span style=\"opacity: 0.80\"> me? </span><span style=\"background-color: hsl(120, 100.00%, 94.39%); opacity: 0.81\" title=\"0.079\">check</span><span style=\"opacity: 0.80\"> out their </span><span style=\"background-color: hsl(120, 100.00%, 91.10%); opacity: 0.82\" title=\"0.154\">site</span><span style=\"opacity: 0.80\">.) to me, this </span><span style=\"background-color: hsl(120, 100.00%, 93.43%); opacity: 0.82\" title=\"0.100\">movie</span><span style=\"opacity: 0.80\"> is a </span><span style=\"background-color: hsl(120, 100.00%, 84.51%); opacity: 0.85\" title=\"0.339\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.35%); opacity: 0.82\" title=\"-0.124\">example</span><span style=\"opacity: 0.80\"> of what not to do in </span><span style=\"background-color: hsl(0, 100.00%, 97.55%); opacity: 0.80\" title=\"-0.024\">filmmaking</span><span style=\"opacity: 0.80\">. the </span><span style=\"background-color: hsl(0, 100.00%, 92.06%); opacity: 0.82\" title=\"-0.131\">dialogue</span><span style=\"opacity: 0.80\"> is very </span><span style=\"background-color: hsl(0, 100.00%, 78.71%); opacity: 0.88\" title=\"-0.534\">bad</span><span style=\"opacity: 0.80\">, the </span><span style=\"background-color: hsl(0, 100.00%, 88.53%); opacity: 0.83\" title=\"-0.221\">acting</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 79.50%); opacity: 0.88\" title=\"-0.506\">worse</span><span style=\"opacity: 0.80\">, the </span><span style=\"background-color: hsl(0, 100.00%, 97.86%); opacity: 0.80\" title=\"-0.020\">cinematography</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 83.27%); opacity: 0.86\" title=\"-0.379\">pathetic</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 93.94%); opacity: 0.81\" title=\"-0.089\">direction</span><span style=\"opacity: 0.80\"> (while perhaps being the </span><span style=\"background-color: hsl(120, 100.00%, 91.69%); opacity: 0.82\" title=\"0.139\">best</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.17%); opacity: 0.86\" title=\"-0.414\">thing</span><span style=\"opacity: 0.80\"> in this </span><span style=\"background-color: hsl(0, 100.00%, 86.34%); opacity: 0.84\" title=\"-0.283\">movie</span><span style=\"opacity: 0.80\">) is </span><span style=\"background-color: hsl(0, 100.00%, 77.03%); opacity: 0.89\" title=\"-0.595\">bad</span><span style=\"opacity: 0.80\">. the </span><span style=\"background-color: hsl(0, 100.00%, 89.06%); opacity: 0.83\" title=\"-0.206\">pacing</span><span style=\"opacity: 0.80\"> is the </span><span style=\"background-color: hsl(0, 100.00%, 63.77%); opacity: 0.97\" title=\"-1.141\">worst</span><span style=\"opacity: 0.80\"> part in this </span><span style=\"background-color: hsl(0, 100.00%, 84.19%); opacity: 0.85\" title=\"-0.349\">movie</span><span style=\"opacity: 0.80\">. a few </span><span style=\"background-color: hsl(0, 100.00%, 99.19%); opacity: 0.80\" title=\"-0.005\">times</span><span style=\"opacity: 0.80\"> in this </span><span style=\"background-color: hsl(0, 100.00%, 91.15%); opacity: 0.82\" title=\"-0.152\">movie</span><span style=\"opacity: 0.80\">, the </span><span style=\"background-color: hsl(0, 100.00%, 98.83%); opacity: 0.80\" title=\"-0.008\">viewer</span><span style=\"opacity: 0.80\"> had to </span><span style=\"background-color: hsl(0, 100.00%, 95.22%); opacity: 0.81\" title=\"-0.063\">wait</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.49%); opacity: 0.81\" title=\"-0.077\">literally</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.56%); opacity: 0.84\" title=\"-0.277\">minutes</span><span style=\"opacity: 0.80\"> for something to </span><span style=\"background-color: hsl(120, 100.00%, 98.61%); opacity: 0.80\" title=\"0.011\">happen</span><span style=\"opacity: 0.80\">. while </span><span style=\"background-color: hsl(0, 100.00%, 86.45%); opacity: 0.84\" title=\"-0.280\">minutes</span><span style=\"opacity: 0.80\"> may not </span><span style=\"background-color: hsl(120, 100.00%, 96.21%); opacity: 0.81\" title=\"0.045\">sound</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.71%); opacity: 0.80\" title=\"-0.022\">like</span><span style=\"opacity: 0.80\"> a very </span><span style=\"background-color: hsl(0, 100.00%, 96.27%); opacity: 0.81\" title=\"-0.044\">long</span><span style=\"opacity: 0.80\"> amount of </span><span style=\"background-color: hsl(120, 100.00%, 92.83%); opacity: 0.82\" title=\"0.113\">time</span><span style=\"opacity: 0.80\">, it can be in a </span><span style=\"background-color: hsl(0, 100.00%, 88.37%); opacity: 0.83\" title=\"-0.225\">movie</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 92.78%); opacity: 0.82\" title=\"-0.114\">particularly</span><span style=\"opacity: 0.80\"> in this one. i am </span><span style=\"background-color: hsl(0, 100.00%, 91.27%); opacity: 0.82\" title=\"-0.149\">sure</span><span style=\"opacity: 0.80\"> it was </span><span style=\"background-color: hsl(0, 100.00%, 87.39%); opacity: 0.84\" title=\"-0.253\">meant</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 97.81%); opacity: 0.80\" title=\"0.021\">create</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 96.79%); opacity: 0.81\" title=\"0.036\">mood</span><span style=\"opacity: 0.80\">, but i was </span><span style=\"background-color: hsl(0, 100.00%, 87.42%); opacity: 0.84\" title=\"-0.252\">just</span><span style=\"opacity: 0.80\"> very </span><span style=\"background-color: hsl(0, 100.00%, 81.74%); opacity: 0.87\" title=\"-0.429\">bored</span><span style=\"opacity: 0.80\">. it </span><span style=\"background-color: hsl(120, 100.00%, 94.27%); opacity: 0.81\" title=\"0.082\">truly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.21%); opacity: 0.85\" title=\"-0.317\">felt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.25%); opacity: 0.83\" title=\"-0.175\">like</span><span style=\"opacity: 0.80\"> ten </span><span style=\"background-color: hsl(0, 100.00%, 87.63%); opacity: 0.84\" title=\"-0.246\">minutes</span><span style=\"opacity: 0.80\">. if \"</span><span style=\"background-color: hsl(120, 100.00%, 96.92%); opacity: 0.81\" title=\"0.034\">suspension</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 93.51%); opacity: 0.81\" title=\"-0.098\">disbelief</span><span style=\"opacity: 0.80\">\" </span><span style=\"background-color: hsl(120, 100.00%, 95.31%); opacity: 0.81\" title=\"0.061\">means</span><span style=\"opacity: 0.80\"> \"almost </span><span style=\"background-color: hsl(0, 100.00%, 94.83%); opacity: 0.81\" title=\"-0.071\">falling</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.31%); opacity: 0.83\" title=\"-0.227\">asleep</span><span style=\"opacity: 0.80\"> during a </span><span style=\"background-color: hsl(0, 100.00%, 95.51%); opacity: 0.81\" title=\"-0.058\">movie</span><span style=\"opacity: 0.80\">\", then this has </span><span style=\"background-color: hsl(120, 100.00%, 87.22%); opacity: 0.84\" title=\"0.257\">plenty</span><span style=\"opacity: 0.80\"> of that. but the </span><span style=\"background-color: hsl(0, 100.00%, 83.86%); opacity: 0.85\" title=\"-0.359\">screaming</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.97%); opacity: 0.84\" title=\"-0.236\">skull</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 94.12%); opacity: 0.81\" title=\"-0.085\">just</span><span style=\"opacity: 0.80\"> so </span><span style=\"background-color: hsl(0, 100.00%, 81.08%); opacity: 0.87\" title=\"-0.451\">horrible</span><span style=\"opacity: 0.80\">, there is no </span><span style=\"background-color: hsl(120, 100.00%, 96.38%); opacity: 0.81\" title=\"0.042\">way</span><span style=\"opacity: 0.80\"> i could have </span><span style=\"background-color: hsl(0, 100.00%, 92.04%); opacity: 0.82\" title=\"-0.131\">possibly</span><span style=\"opacity: 0.80\"> even </span><span style=\"background-color: hsl(120, 100.00%, 92.62%); opacity: 0.82\" title=\"0.118\">gotten</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.76%); opacity: 0.81\" title=\"0.053\">interested</span><span style=\"opacity: 0.80\"> in anything that was </span><span style=\"background-color: hsl(0, 100.00%, 93.19%); opacity: 0.82\" title=\"-0.105\">actually</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.32%); opacity: 0.80\" title=\"-0.028\">going</span><span style=\"opacity: 0.80\"> on in the </span><span style=\"background-color: hsl(120, 100.00%, 93.32%); opacity: 0.82\" title=\"0.102\">film</span><span style=\"opacity: 0.80\">, and thus the \"</span><span style=\"background-color: hsl(120, 100.00%, 96.92%); opacity: 0.81\" title=\"0.034\">suspension</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 93.51%); opacity: 0.81\" title=\"-0.098\">disbelief</span><span style=\"opacity: 0.80\">\" was indeed </span><span style=\"background-color: hsl(120, 100.00%, 95.55%); opacity: 0.81\" title=\"0.057\">non</span><span style=\"opacity: 0.80\">-existant. one of the </span><span style=\"background-color: hsl(0, 100.00%, 71.01%); opacity: 0.93\" title=\"-0.830\">worst</span><span style=\"opacity: 0.80\">, and </span><span style=\"background-color: hsl(120, 100.00%, 98.56%); opacity: 0.80\" title=\"0.011\">probably</span><span style=\"opacity: 0.80\"> the most </span><span style=\"background-color: hsl(0, 100.00%, 70.23%); opacity: 0.93\" title=\"-0.862\">boring</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.81%); opacity: 0.83\" title=\"-0.213\">movie</span><span style=\"opacity: 0.80\"> i have ever </span><span style=\"background-color: hsl(120, 100.00%, 88.95%); opacity: 0.83\" title=\"0.209\">seen</span><span style=\"opacity: 0.80\">. 1/</span><span style=\"background-color: hsl(120, 100.00%, 94.58%); opacity: 0.81\" title=\"0.076\">10</span>\n",
              "</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<p style=background-color:black;color:white;font-weight:bold;padding:4px>Bad Movie #3 üçÖ</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "<p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "<span style=\"opacity: 0.80\">i </span><span style=\"background-color: hsl(0, 100.00%, 87.78%); opacity: 0.84\" title=\"-0.367\">rented</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(0, 100.00%, 91.90%); opacity: 0.82\" title=\"-0.204\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.54%); opacity: 0.85\" title=\"0.466\">today</span><span style=\"opacity: 0.80\">... </span><span style=\"background-color: hsl(0, 100.00%, 64.32%); opacity: 0.97\" title=\"-1.694\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.75%); opacity: 0.83\" title=\"-0.326\">movie</span><span style=\"opacity: 0.80\"> ever. it was a </span><span style=\"background-color: hsl(0, 100.00%, 83.39%); opacity: 0.86\" title=\"-0.568\">total</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.995\">waste</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 89.79%); opacity: 0.83\" title=\"-0.284\">time</span><span style=\"opacity: 0.80\"> and a </span><span style=\"background-color: hsl(0, 100.00%, 78.29%); opacity: 0.88\" title=\"-0.833\">horrible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.00%); opacity: 0.81\" title=\"0.133\">story</span><span style=\"opacity: 0.80\">. the </span><span style=\"background-color: hsl(0, 100.00%, 87.63%); opacity: 0.84\" title=\"-0.373\">acting</span><span style=\"opacity: 0.80\"> was </span><span style=\"background-color: hsl(0, 100.00%, 73.25%); opacity: 0.91\" title=\"-1.123\">horrible</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 89.49%); opacity: 0.83\" title=\"0.296\">especially</span><span style=\"opacity: 0.80\"> by the </span><span style=\"background-color: hsl(0, 100.00%, 94.20%); opacity: 0.81\" title=\"-0.127\">actress</span><span style=\"opacity: 0.80\"> of \"</span><span style=\"background-color: hsl(0, 100.00%, 98.92%); opacity: 0.80\" title=\"-0.011\">sai</span><span style=\"opacity: 0.80\">\". she was so </span><span style=\"background-color: hsl(0, 100.00%, 82.10%); opacity: 0.86\" title=\"-0.632\">bad</span><span style=\"opacity: 0.80\"> it was </span><span style=\"background-color: hsl(0, 100.00%, 81.47%); opacity: 0.87\" title=\"-0.664\">ridiculous</span><span style=\"opacity: 0.80\">. i cannot </span><span style=\"background-color: hsl(0, 100.00%, 95.15%); opacity: 0.81\" title=\"-0.098\">tell</span><span style=\"opacity: 0.80\"> if it was her </span><span style=\"background-color: hsl(0, 100.00%, 77.60%); opacity: 0.89\" title=\"-0.871\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.03%); opacity: 0.83\" title=\"-0.314\">acting</span><span style=\"opacity: 0.80\"> or because the </span><span style=\"background-color: hsl(0, 100.00%, 96.52%); opacity: 0.81\" title=\"-0.061\">character</span><span style=\"opacity: 0.80\"> was </span><span style=\"background-color: hsl(0, 100.00%, 86.82%); opacity: 0.84\" title=\"-0.408\">just</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(0, 100.00%, 80.93%); opacity: 0.87\" title=\"-0.693\">stupid</span><span style=\"opacity: 0.80\"> in the first </span><span style=\"background-color: hsl(120, 100.00%, 97.56%); opacity: 0.80\" title=\"0.037\">place</span><span style=\"opacity: 0.80\">. i cannot even get my </span><span style=\"background-color: hsl(120, 100.00%, 93.25%); opacity: 0.82\" title=\"0.157\">mind</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.08%); opacity: 0.84\" title=\"0.354\">wrapped</span><span style=\"opacity: 0.80\"> around </span><span style=\"background-color: hsl(0, 100.00%, 86.25%); opacity: 0.84\" title=\"-0.434\">just</span><span style=\"opacity: 0.80\"> how </span><span style=\"background-color: hsl(0, 100.00%, 69.05%); opacity: 0.94\" title=\"-1.383\">awful</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 79.49%); opacity: 0.88\" title=\"-0.768\">pointless</span><span style=\"opacity: 0.80\"> this whole </span><span style=\"background-color: hsl(120, 100.00%, 93.18%); opacity: 0.82\" title=\"0.159\">movie</span><span style=\"opacity: 0.80\"> was. i am </span><span style=\"background-color: hsl(120, 100.00%, 80.02%); opacity: 0.87\" title=\"0.740\">surprised</span><span style=\"opacity: 0.80\"> someone even </span><span style=\"background-color: hsl(120, 100.00%, 97.32%); opacity: 0.80\" title=\"0.042\">thought</span><span style=\"opacity: 0.80\"> it was a </span><span style=\"background-color: hsl(0, 100.00%, 97.02%); opacity: 0.80\" title=\"-0.049\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.90%); opacity: 0.86\" title=\"-0.593\">idea</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 97.27%); opacity: 0.80\" title=\"0.043\">film</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(0, 100.00%, 95.84%); opacity: 0.81\" title=\"-0.079\">movie</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 83.29%); opacity: 0.86\" title=\"-0.573\">bother</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 91.11%); opacity: 0.82\" title=\"0.233\">release</span><span style=\"opacity: 0.80\"> it. if you are </span><span style=\"background-color: hsl(0, 100.00%, 92.21%); opacity: 0.82\" title=\"-0.193\">looking</span><span style=\"opacity: 0.80\"> for a </span><span style=\"background-color: hsl(120, 100.00%, 99.79%); opacity: 0.80\" title=\"0.001\">good</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.52%); opacity: 0.80\" title=\"-0.018\">vampire</span><span style=\"opacity: 0.80\">/</span><span style=\"background-color: hsl(0, 100.00%, 89.20%); opacity: 0.83\" title=\"-0.307\">horror</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.55%); opacity: 0.81\" title=\"-0.147\">flick</span><span style=\"opacity: 0.80\">.. this is not the </span><span style=\"background-color: hsl(0, 100.00%, 97.87%); opacity: 0.80\" title=\"-0.030\">movie</span><span style=\"opacity: 0.80\"> for you. move </span><span style=\"background-color: hsl(120, 100.00%, 96.53%); opacity: 0.81\" title=\"0.061\">right</span><span style=\"opacity: 0.80\"> along! it is a </span><span style=\"background-color: hsl(0, 100.00%, 61.96%); opacity: 0.99\" title=\"-1.856\">waste</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 82.10%); opacity: 0.86\" title=\"-0.633\">time</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 79.68%); opacity: 0.88\" title=\"-0.758\">money</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 99.02%); opacity: 0.80\" title=\"-0.010\">heck</span><span style=\"opacity: 0.80\">, i would not even </span><span style=\"background-color: hsl(0, 100.00%, 96.01%); opacity: 0.81\" title=\"-0.074\">download</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(0, 100.00%, 99.06%); opacity: 0.80\" title=\"-0.009\">movie</span><span style=\"opacity: 0.80\"> if someone </span><span style=\"background-color: hsl(0, 100.00%, 85.25%); opacity: 0.85\" title=\"-0.480\">paid</span><span style=\"opacity: 0.80\"> me. this </span><span style=\"background-color: hsl(0, 100.00%, 88.43%); opacity: 0.83\" title=\"-0.339\">movie</span><span style=\"opacity: 0.80\"> is so </span><span style=\"background-color: hsl(0, 100.00%, 80.93%); opacity: 0.87\" title=\"-0.692\">bad</span><span style=\"opacity: 0.80\"> it </span><span style=\"background-color: hsl(0, 100.00%, 91.67%); opacity: 0.82\" title=\"-0.212\">does</span><span style=\"opacity: 0.80\"> not even </span><span style=\"background-color: hsl(0, 100.00%, 83.26%); opacity: 0.86\" title=\"-0.575\">deserve</span><span style=\"opacity: 0.80\"> a \"1\". i </span><span style=\"background-color: hsl(120, 100.00%, 94.29%); opacity: 0.81\" title=\"0.124\">wish</span><span style=\"opacity: 0.80\"> i could give it a \"0\"!</span>\n",
              "</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<p style=background-color:black;color:white;font-weight:bold;padding:4px>Bad Movie #4 üçÖ</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "<p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "<span style=\"opacity: 0.80\">this is </span><span style=\"background-color: hsl(0, 100.00%, 86.65%); opacity: 0.84\" title=\"-0.208\">just</span><span style=\"opacity: 0.80\"> the same </span><span style=\"background-color: hsl(0, 100.00%, 89.56%); opacity: 0.83\" title=\"-0.146\">old</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.58%); opacity: 0.87\" title=\"-0.355\">crap</span><span style=\"opacity: 0.80\"> that is </span><span style=\"background-color: hsl(0, 100.00%, 95.16%); opacity: 0.81\" title=\"-0.049\">spewed</span><span style=\"opacity: 0.80\"> from </span><span style=\"background-color: hsl(0, 100.00%, 86.69%); opacity: 0.84\" title=\"-0.207\">amateur</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.16%); opacity: 0.84\" title=\"-0.175\">idiots</span><span style=\"opacity: 0.80\"> who have no </span><span style=\"background-color: hsl(0, 100.00%, 90.90%); opacity: 0.82\" title=\"-0.120\">clue</span><span style=\"opacity: 0.80\"> how to </span><span style=\"background-color: hsl(0, 100.00%, 79.65%); opacity: 0.88\" title=\"-0.379\">make</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 85.17%); opacity: 0.85\" title=\"-0.241\">movie</span><span style=\"opacity: 0.80\">--</span><span style=\"background-color: hsl(120, 100.00%, 91.44%); opacity: 0.82\" title=\"0.110\">gee</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.05%); opacity: 0.84\" title=\"-0.177\">maybe</span><span style=\"opacity: 0.80\"> that is why it is a </span><span style=\"background-color: hsl(0, 100.00%, 85.98%); opacity: 0.84\" title=\"-0.223\">straight</span><span style=\"opacity: 0.80\">-to-</span><span style=\"background-color: hsl(0, 100.00%, 93.32%); opacity: 0.82\" title=\"-0.077\">video</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.74%); opacity: 0.82\" title=\"-0.105\">want</span><span style=\"opacity: 0.80\"> to-be </span><span style=\"background-color: hsl(0, 100.00%, 87.10%); opacity: 0.84\" title=\"-0.198\">movie</span><span style=\"opacity: 0.80\">! i </span><span style=\"background-color: hsl(0, 100.00%, 77.17%); opacity: 0.89\" title=\"-0.447\">guess</span><span style=\"opacity: 0.80\"> it is my </span><span style=\"background-color: hsl(0, 100.00%, 94.29%); opacity: 0.81\" title=\"-0.062\">fault</span><span style=\"opacity: 0.80\"> for </span><span style=\"background-color: hsl(0, 100.00%, 95.58%); opacity: 0.81\" title=\"-0.043\">actually</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.10%); opacity: 0.84\" title=\"-0.198\">spending</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.04%); opacity: 0.86\" title=\"-0.292\">money</span><span style=\"opacity: 0.80\"> to see it (one of the </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.996\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.01%); opacity: 0.80\" title=\"-0.024\">decisions</span><span style=\"opacity: 0.80\"> i have ever made). what a </span><span style=\"background-color: hsl(0, 100.00%, 64.26%); opacity: 0.97\" title=\"-0.848\">waste</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 93.08%); opacity: 0.82\" title=\"-0.081\">usually</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.33%); opacity: 0.81\" title=\"-0.046\">like</span><span style=\"opacity: 0.80\"> b </span><span style=\"background-color: hsl(120, 100.00%, 87.95%); opacity: 0.84\" title=\"0.179\">movies</span><span style=\"opacity: 0.80\">, some of them are </span><span style=\"background-color: hsl(0, 100.00%, 98.49%); opacity: 0.80\" title=\"-0.009\">actually</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.91%); opacity: 0.84\" title=\"0.202\">quite</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.98%); opacity: 0.84\" title=\"0.223\">good</span><span style=\"opacity: 0.80\">--but this is </span><span style=\"background-color: hsl(0, 100.00%, 94.78%); opacity: 0.81\" title=\"-0.054\">just</span><span style=\"opacity: 0.80\"> too </span><span style=\"background-color: hsl(0, 100.00%, 77.32%); opacity: 0.89\" title=\"-0.443\">ridiculous</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 75.22%); opacity: 0.90\" title=\"-0.502\">stupid</span><span style=\"opacity: 0.80\"> to even be </span><span style=\"background-color: hsl(0, 100.00%, 98.50%); opacity: 0.80\" title=\"-0.009\">funny</span><span style=\"opacity: 0.80\">. the </span><span style=\"background-color: hsl(0, 100.00%, 88.84%); opacity: 0.83\" title=\"-0.161\">losers</span><span style=\"opacity: 0.80\"> that made this </span><span style=\"background-color: hsl(0, 100.00%, 84.31%); opacity: 0.85\" title=\"-0.261\">junk</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.44%); opacity: 0.85\" title=\"-0.258\">deserve</span><span style=\"opacity: 0.80\"> to be put out of </span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.82\" title=\"0.075\">business</span><span style=\"opacity: 0.80\"> for </span><span style=\"background-color: hsl(0, 100.00%, 69.74%); opacity: 0.93\" title=\"-0.668\">wasting</span><span style=\"opacity: 0.80\"> everyone is </span><span style=\"background-color: hsl(0, 100.00%, 76.58%); opacity: 0.89\" title=\"-0.464\">time</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 75.39%); opacity: 0.90\" title=\"-0.497\">money</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.98%); opacity: 0.85\" title=\"-0.246\">making</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(0, 100.00%, 91.50%); opacity: 0.82\" title=\"-0.109\">movie</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(120, 100.00%, 94.60%); opacity: 0.81\" title=\"0.057\">obviously</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.39%); opacity: 0.85\" title=\"-0.236\">does</span><span style=\"opacity: 0.80\"> not even </span><span style=\"background-color: hsl(0, 100.00%, 76.94%); opacity: 0.89\" title=\"-0.453\">deserve</span><span style=\"opacity: 0.80\"> to be on </span><span style=\"background-color: hsl(0, 100.00%, 94.49%); opacity: 0.81\" title=\"-0.059\">film</span><span style=\"opacity: 0.80\">! these so-</span><span style=\"background-color: hsl(0, 100.00%, 84.12%); opacity: 0.85\" title=\"-0.266\">called</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.17%); opacity: 0.80\" title=\"0.012\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.88%); opacity: 0.82\" title=\"-0.085\">makers</span><span style=\"opacity: 0.80\"> have </span><span style=\"background-color: hsl(0, 100.00%, 91.77%); opacity: 0.82\" title=\"-0.104\">absolutely</span><span style=\"opacity: 0.80\"> no </span><span style=\"background-color: hsl(0, 100.00%, 92.01%); opacity: 0.82\" title=\"-0.100\">talent</span><span style=\"opacity: 0.80\">! </span><span style=\"background-color: hsl(0, 100.00%, 72.71%); opacity: 0.92\" title=\"-0.577\">stupid</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.85%); opacity: 0.86\" title=\"-0.322\">plot</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 67.11%); opacity: 0.95\" title=\"-0.753\">horrible</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.04%); opacity: 0.84\" title=\"-0.199\">acting</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(120, 100.00%, 79.23%); opacity: 0.88\" title=\"0.390\">especially</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 93.92%); opacity: 0.81\" title=\"-0.067\">drag</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.05%); opacity: 0.82\" title=\"0.082\">queens</span><span style=\"opacity: 0.80\">--what </span><span style=\"background-color: hsl(120, 100.00%, 97.42%); opacity: 0.80\" title=\"0.020\">sicko</span><span style=\"opacity: 0.80\"> would </span><span style=\"background-color: hsl(0, 100.00%, 95.58%); opacity: 0.81\" title=\"-0.043\">actually</span><span style=\"opacity: 0.80\"> find that </span><span style=\"background-color: hsl(120, 100.00%, 97.56%); opacity: 0.80\" title=\"0.018\">sexy</span><span style=\"opacity: 0.80\">?!), </span><span style=\"background-color: hsl(0, 100.00%, 70.26%); opacity: 0.93\" title=\"-0.652\">lame</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.76%); opacity: 0.87\" title=\"-0.324\">writing</span><span style=\"opacity: 0.80\"> (if there even was a </span><span style=\"background-color: hsl(0, 100.00%, 82.86%); opacity: 0.86\" title=\"-0.297\">script</span><span style=\"opacity: 0.80\">--seems </span><span style=\"background-color: hsl(120, 100.00%, 95.18%); opacity: 0.81\" title=\"0.049\">like</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 91.93%); opacity: 0.82\" title=\"-0.101\">kind</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(0, 100.00%, 93.19%); opacity: 0.82\" title=\"-0.079\">bull</span><span style=\"opacity: 0.80\">**** someone </span><span style=\"background-color: hsl(0, 100.00%, 91.89%); opacity: 0.82\" title=\"-0.102\">just</span><span style=\"opacity: 0.80\"> made up on the </span><span style=\"background-color: hsl(120, 100.00%, 91.25%); opacity: 0.82\" title=\"0.114\">spot</span><span style=\"opacity: 0.80\">) what is </span><span style=\"background-color: hsl(120, 100.00%, 78.55%); opacity: 0.88\" title=\"0.409\">stunning</span><span style=\"opacity: 0.80\"> about this </span><span style=\"background-color: hsl(120, 100.00%, 95.18%); opacity: 0.81\" title=\"0.048\">movie</span><span style=\"opacity: 0.80\"> is its </span><span style=\"background-color: hsl(0, 100.00%, 80.41%); opacity: 0.87\" title=\"-0.359\">utter</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.35%); opacity: 0.87\" title=\"-0.361\">lack</span><span style=\"opacity: 0.80\"> of anything well-done at all. how much </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.143\">attention</span><span style=\"opacity: 0.80\"> to detail would it take to </span><span style=\"background-color: hsl(0, 100.00%, 97.07%); opacity: 0.80\" title=\"-0.024\">insure</span><span style=\"opacity: 0.80\"> that every </span><span style=\"background-color: hsl(120, 100.00%, 94.84%); opacity: 0.81\" title=\"0.053\">frame</span><span style=\"opacity: 0.80\"> of a </span><span style=\"background-color: hsl(120, 100.00%, 89.09%); opacity: 0.83\" title=\"0.156\">film</span><span style=\"opacity: 0.80\"> would be so </span><span style=\"background-color: hsl(0, 100.00%, 93.47%); opacity: 0.82\" title=\"-0.075\">far</span><span style=\"opacity: 0.80\"> below any </span><span style=\"background-color: hsl(0, 100.00%, 92.11%); opacity: 0.82\" title=\"-0.098\">reasonable</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.21%); opacity: 0.83\" title=\"-0.174\">standards</span><span style=\"opacity: 0.80\">? i do not </span><span style=\"background-color: hsl(120, 100.00%, 92.84%); opacity: 0.82\" title=\"0.085\">think</span><span style=\"opacity: 0.80\"> it would be </span><span style=\"background-color: hsl(0, 100.00%, 92.02%); opacity: 0.82\" title=\"-0.100\">possible</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(0, 100.00%, 88.21%); opacity: 0.83\" title=\"-0.174\">make</span><span style=\"opacity: 0.80\"> such a </span><span style=\"background-color: hsl(0, 100.00%, 65.93%); opacity: 0.96\" title=\"-0.792\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.23%); opacity: 0.85\" title=\"-0.263\">movie</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.28%); opacity: 0.81\" title=\"0.062\">intentionally</span><span style=\"opacity: 0.80\">, and it is </span><span style=\"background-color: hsl(0, 100.00%, 96.64%); opacity: 0.81\" title=\"-0.029\">inconceivable</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(0, 100.00%, 97.67%); opacity: 0.80\" title=\"-0.017\">sheer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.94%); opacity: 0.89\" title=\"-0.425\">bad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.62%); opacity: 0.83\" title=\"0.165\">luck</span><span style=\"opacity: 0.80\"> could </span><span style=\"background-color: hsl(0, 100.00%, 93.33%); opacity: 0.82\" title=\"-0.077\">produce</span><span style=\"opacity: 0.80\"> such </span><span style=\"background-color: hsl(0, 100.00%, 99.09%); opacity: 0.80\" title=\"-0.004\">consistently</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 63.48%); opacity: 0.98\" title=\"-0.874\">awful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.63%); opacity: 0.81\" title=\"0.072\">results</span><span style=\"opacity: 0.80\">. anyway, </span><span style=\"background-color: hsl(0, 100.00%, 76.02%); opacity: 0.90\" title=\"-0.479\">avoid</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(0, 100.00%, 88.46%); opacity: 0.83\" title=\"-0.169\">stink</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.79%); opacity: 0.85\" title=\"-0.250\">bomb</span><span style=\"opacity: 0.80\"> at all </span><span style=\"background-color: hsl(0, 100.00%, 82.82%); opacity: 0.86\" title=\"-0.298\">costs</span><span style=\"opacity: 0.80\">!!!!!!!!!!!!!!!!</span>\n",
              "</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<p style=background-color:black;color:white;font-weight:bold;padding:4px>Bad Movie #5 üçÖ</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "<p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "<span style=\"opacity: 0.80\">this was one of the </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-3.563\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.04%); opacity: 0.88\" title=\"-1.512\">movies</span><span style=\"opacity: 0.80\"> i have ever </span><span style=\"background-color: hsl(0, 100.00%, 88.45%); opacity: 0.83\" title=\"-0.604\">seen</span><span style=\"opacity: 0.80\">. the </span><span style=\"background-color: hsl(0, 100.00%, 88.97%); opacity: 0.83\" title=\"-0.566\">plot</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 70.86%); opacity: 0.93\" title=\"-2.265\">awful</span><span style=\"opacity: 0.80\">, and the </span><span style=\"background-color: hsl(0, 100.00%, 89.84%); opacity: 0.83\" title=\"-0.503\">acting</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 79.50%); opacity: 0.88\" title=\"-1.371\">worse</span><span style=\"opacity: 0.80\">. the </span><span style=\"background-color: hsl(0, 100.00%, 98.51%); opacity: 0.80\" title=\"-0.032\">jokes</span><span style=\"opacity: 0.80\"> that are </span><span style=\"background-color: hsl(0, 100.00%, 91.76%); opacity: 0.82\" title=\"-0.373\">attempted</span><span style=\"opacity: 0.80\"> absolutley </span><span style=\"background-color: hsl(0, 100.00%, 95.98%); opacity: 0.81\" title=\"-0.134\">suck</span><span style=\"opacity: 0.80\">. do not </span><span style=\"background-color: hsl(0, 100.00%, 84.75%); opacity: 0.85\" title=\"-0.898\">bother</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(0, 100.00%, 63.07%); opacity: 0.98\" title=\"-3.178\">waste</span><span style=\"opacity: 0.80\"> your </span><span style=\"background-color: hsl(0, 100.00%, 83.86%); opacity: 0.85\" title=\"-0.975\">time</span><span style=\"opacity: 0.80\"> on a </span><span style=\"background-color: hsl(0, 100.00%, 86.47%); opacity: 0.84\" title=\"-0.757\">dumb</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.07%); opacity: 0.81\" title=\"-0.233\">movie</span><span style=\"opacity: 0.80\"> such as this. and if for some </span><span style=\"background-color: hsl(0, 100.00%, 86.37%); opacity: 0.84\" title=\"-0.766\">reason</span><span style=\"opacity: 0.80\"> that you do </span><span style=\"background-color: hsl(0, 100.00%, 92.36%); opacity: 0.82\" title=\"-0.335\">want</span><span style=\"opacity: 0.80\"> to see this </span><span style=\"background-color: hsl(120, 100.00%, 93.39%); opacity: 0.82\" title=\"0.272\">movie</span><span style=\"opacity: 0.80\">, do not </span><span style=\"background-color: hsl(120, 100.00%, 91.45%); opacity: 0.82\" title=\"0.393\">watch</span><span style=\"opacity: 0.80\"> it with your </span><span style=\"background-color: hsl(0, 100.00%, 96.02%); opacity: 0.81\" title=\"-0.132\">parents</span><span style=\"opacity: 0.80\">.</span>\n",
              "</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i, review in enumerate(worst5):\n",
        "    style = 'background-color:black;color:white;font-weight:bold;padding:4px'\n",
        "    display(HTML(f\"<p style={style}>Bad Movie #{i+1} üçÖ</p>\"))\n",
        "    eli5_html(clf, vec, review)"
      ],
      "id": "1130af96"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9b746bf"
      },
      "source": [
        "### What are the **5 best** movie review in the test set according to your model? üèÜ"
      ],
      "id": "a9b746bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5931802f"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# Find indices of 5 best reviews\n",
        "best5 = x_test_raw[np.flip(np.argsort(np.abs(y_pred_proba)), axis=0)[:5]]"
      ],
      "id": "5931802f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1250cc2a"
      },
      "outputs": [],
      "source": [
        "for i, review in enumerate(best5):\n",
        "    display(HTML(f\"<p style={style}>Good Movie #{i+1} üèÜ</p>\"))\n",
        "    eli5_html(clf, vec, review)"
      ],
      "id": "1250cc2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f55f479a"
      },
      "source": [
        "What are the **5 most 'meh'** movie review in the test set according to your model? üòê\\\n",
        "That is, which reviews are the most neutral according to your model?\\\n",
        "Upon reading some of these reviews you may find their sentiment to actually *not* be very ambiguous. What might be confusing our model?"
      ],
      "id": "f55f479a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae42fdec"
      },
      "outputs": [],
      "source": [
        "# please fill this code block!\n",
        "# Find indices of the 5 most neutral reviews\n",
        "meh5 = x_test_raw[np.argsort(np.abs(y_pred_proba - 0.5))[:5]]"
      ],
      "id": "ae42fdec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cccc9ae"
      },
      "outputs": [],
      "source": [
        "for i, review in enumerate(meh5):\n",
        "    display(HTML(f\"<p style={style}>'Meh' Movie #{i+1} üòê</p>\"))\n",
        "    eli5_html(clf, vec, review)"
      ],
      "id": "7cccc9ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53c58acd"
      },
      "source": [
        "Despite some difficulties with a few of the 'meh' movies, our model is actually pretty good! In fact, it works so well you can actually use it to find _mistakes_ in the manually labeled data!\\\n",
        "This can be done by inspecting which training observation predictions differ the most from the provided labels.\\"
      ],
      "id": "53c58acd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7d659c3"
      },
      "source": [
        "**Write your own review**\n",
        "\n",
        "Finally, you can try writing a review of your own and see what your model does with it!"
      ],
      "id": "a7d659c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf078e01"
      },
      "outputs": [],
      "source": [
        "my_review = \"\"\"\n",
        "            I have recently watched the movie 'Into the spiderverse'. It was SO good:\n",
        "            this new type of animation style is so interesting and appealing to me.\n",
        "            My friends said the frames are clacky and uncomfortable, but I believe this\n",
        "            is not true, since each frame is a wonderful piece of artwork with a diversity\n",
        "            of coloring combinations and shape languages. Besides, the plot is well-written.\n",
        "            There are many minor details to show the emotions of the main character, how he grows\n",
        "            and overcoming his fear. The interactions between characters are funny with lots\n",
        "            of Peter Parker from different spiderverses.\n",
        "            \"\"\"\n",
        "\n",
        "# Remove punctuation using your regex from earlier\n",
        "my_review = re.sub(punc_regex, '', my_review)\n",
        "# Remove leading & trailing whitespace\n",
        "# and put into a numpy array (which the model expects)\n",
        "my_review = np.array([my_review.strip()])\n",
        "my_review"
      ],
      "id": "cf078e01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abdc48fd"
      },
      "outputs": [],
      "source": [
        "my_review_proba = pipe.predict_proba(my_review)[:,1][0]\n",
        "my_review_label = pipe.predict(my_review)[0]\n",
        "print('predicted class:', my_review_label)\n",
        "print('predicted probability:', my_review_proba)"
      ],
      "id": "abdc48fd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8de285ed"
      },
      "outputs": [],
      "source": [
        "display(HTML(f\"<p style={style}>My Review üçø</p>\"))\n",
        "eli5_html(clf, vec, my_review[0])"
      ],
      "id": "8de285ed"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQwF54V5m0WG"
      },
      "outputs": [],
      "source": [],
      "id": "BQwF54V5m0WG"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0fffa9cf",
        "a9b746bf"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "300px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}