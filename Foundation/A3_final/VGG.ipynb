{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22fa27e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-28T03:36:24.240026Z",
     "iopub.status.busy": "2023-11-28T03:36:24.239371Z",
     "iopub.status.idle": "2023-11-28T03:36:25.020687Z",
     "shell.execute_reply": "2023-11-28T03:36:25.019909Z"
    },
    "papermill": {
     "duration": 0.78943,
     "end_time": "2023-11-28T03:36:25.023136",
     "exception": false,
     "start_time": "2023-11-28T03:36:24.233706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98210138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:36:25.032730Z",
     "iopub.status.busy": "2023-11-28T03:36:25.032334Z",
     "iopub.status.idle": "2023-11-28T03:36:56.440238Z",
     "shell.execute_reply": "2023-11-28T03:36:56.439292Z"
    },
    "papermill": {
     "duration": 31.418286,
     "end_time": "2023-11-28T03:36:56.445762",
     "exception": false,
     "start_time": "2023-11-28T03:36:25.027476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10763, 256, 256, 3)\n",
      "(10763,)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "x = joblib.load(\"/kaggle/input/preprocessing-done/x_data.joblib\")\n",
    "y = joblib.load(\"/kaggle/input/preprocessing-done/y_data.joblib\")\n",
    "img_ids = joblib.load(\"/kaggle/input/preprocessing-done/img_ids.joblib\")\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40aa186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:36:56.455061Z",
     "iopub.status.busy": "2023-11-28T03:36:56.454717Z",
     "iopub.status.idle": "2023-11-28T03:36:58.364596Z",
     "shell.execute_reply": "2023-11-28T03:36:58.363516Z"
    },
    "papermill": {
     "duration": 1.916807,
     "end_time": "2023-11-28T03:36:58.366662",
     "exception": false,
     "start_time": "2023-11-28T03:36:56.449855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 256, 256, 3)\n",
      "(1200, 256, 256, 3)\n",
      "(6800,)\n",
      "(1200,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1=x[:8000]\n",
    "y1=y[:8000]\n",
    "img_ids1=img_ids[:8000]\n",
    "x_train, x_test, y_train, y_test, img_ids_train, img_ids_test = train_test_split(x1, y1, img_ids1, test_size=0.15, shuffle=True, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f13903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:36:58.376670Z",
     "iopub.status.busy": "2023-11-28T03:36:58.376353Z",
     "iopub.status.idle": "2023-11-28T03:37:14.611306Z",
     "shell.execute_reply": "2023-11-28T03:37:14.610435Z"
    },
    "papermill": {
     "duration": 16.242333,
     "end_time": "2023-11-28T03:37:14.613419",
     "exception": false,
     "start_time": "2023-11-28T03:36:58.371086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44287fd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:37:14.623822Z",
     "iopub.status.busy": "2023-11-28T03:37:14.622718Z",
     "iopub.status.idle": "2023-11-28T03:37:14.739204Z",
     "shell.execute_reply": "2023-11-28T03:37:14.738305Z"
    },
    "papermill": {
     "duration": 0.123721,
     "end_time": "2023-11-28T03:37:14.741393",
     "exception": false,
     "start_time": "2023-11-28T03:37:14.617672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8282707c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:37:14.751836Z",
     "iopub.status.busy": "2023-11-28T03:37:14.751484Z",
     "iopub.status.idle": "2023-11-28T03:43:07.818649Z",
     "shell.execute_reply": "2023-11-28T03:43:07.817752Z"
    },
    "papermill": {
     "duration": 353.07464,
     "end_time": "2023-11-28T03:43:07.820865",
     "exception": false,
     "start_time": "2023-11-28T03:37:14.746225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Epoch 1/5\n",
      "107/107 [==============================] - 82s 616ms/step - loss: 3.8495 - accuracy: 0.3334 - val_loss: 1.4178 - val_accuracy: 0.4017\n",
      "Epoch 2/5\n",
      "107/107 [==============================] - 58s 546ms/step - loss: 1.3217 - accuracy: 0.4566 - val_loss: 1.3941 - val_accuracy: 0.4275\n",
      "Epoch 3/5\n",
      "107/107 [==============================] - 59s 547ms/step - loss: 1.1668 - accuracy: 0.5272 - val_loss: 1.2972 - val_accuracy: 0.4650\n",
      "Epoch 4/5\n",
      "107/107 [==============================] - 58s 543ms/step - loss: 1.0464 - accuracy: 0.5809 - val_loss: 1.3039 - val_accuracy: 0.4525\n",
      "Epoch 5/5\n",
      "107/107 [==============================] - 58s 541ms/step - loss: 1.0023 - accuracy: 0.5987 - val_loss: 1.2711 - val_accuracy: 0.4942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/1695736743.py:24: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(vgg_model, \"/kaggle/working/vgg_model.h5\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 9s 145ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "num_classes = 6\n",
    "devices = ['/GPU:0', '/GPU:1']\n",
    "strategy = tf.distribute.MirroredStrategy(devices=devices)\n",
    "with strategy.scope(): \n",
    "    # 加载预训练的VGG16模型（不包括顶部分类层）\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256,256, 3))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "    # Customize the top classification layers\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)  # 添加 Dropout 层，丢弃比例为 0.2\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    #x = Dropout(0.2)(x)  # 添加 Dropout 层，丢弃比例为 0.2\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)  # Replace num_classes with the number of classes in your dataset\n",
    "\n",
    "    vgg_model= Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    vgg_model.compile(optimizer=Adam(lr=0.0001),  loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # 编译模型\n",
    "    vgg_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test,y_test))  # 训练模型\n",
    "    save_model(vgg_model, \"/kaggle/working/vgg_model.h5\")\n",
    "    predictions= vgg_model.predict(x_test)\n",
    "    y_pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34866c8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:43:07.972809Z",
     "iopub.status.busy": "2023-11-28T03:43:07.972380Z",
     "iopub.status.idle": "2023-11-28T03:43:07.980835Z",
     "shell.execute_reply": "2023-11-28T03:43:07.979973Z"
    },
    "papermill": {
     "duration": 0.107998,
     "end_time": "2023-11-28T03:43:07.982701",
     "exception": false,
     "start_time": "2023-11-28T03:43:07.874703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49416666666666664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7a8264b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:43:08.083289Z",
     "iopub.status.busy": "2023-11-28T03:43:08.083007Z",
     "iopub.status.idle": "2023-11-28T03:43:08.100203Z",
     "shell.execute_reply": "2023-11-28T03:43:08.099385Z"
    },
    "papermill": {
     "duration": 0.069772,
     "end_time": "2023-11-28T03:43:08.102149",
     "exception": false,
     "start_time": "2023-11-28T03:43:08.032377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5372340425531915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_majority_label(image_ids, labels):\n",
    "    id_label_map = {}  # 创建一个空的字典来存储image_id和对应的label\n",
    "\n",
    "    # 遍历image_ids和labels列表\n",
    "    for image_id, label in zip(image_ids, labels):\n",
    "        if image_id in id_label_map:\n",
    "            id_label_map[image_id].append(label)\n",
    "        else:\n",
    "            id_label_map[image_id] = [label]\n",
    "\n",
    "    majority_labels = {}  # 创建一个空的字典来存储每个唯一image_id的多数投票label\n",
    "\n",
    "    # 对字典中的每个唯一image_id的label列表进行多数投票\n",
    "    for image_id, label_list in id_label_map.items():\n",
    "        label_counts = Counter(label_list)\n",
    "        majority_label = label_counts.most_common(1)[0][0]\n",
    "        majority_labels[image_id] = majority_label\n",
    "\n",
    "    return majority_labels\n",
    "\n",
    "y_votingpred=find_majority_label(img_ids_test, y_pred)\n",
    "# 对图像 ID 进行去重\n",
    "unique_img_ids = np.unique(img_ids_test)\n",
    "\n",
    "# 根据去重后的图像 ID，获取对应的真实标签和预测标签\n",
    "y_test_matched = []\n",
    "y_test_matched = np.array([y_test[np.where(img_ids_test == img_id)[0][0]] for img_id in unique_img_ids])\n",
    "y_votingpred_matched = np.array([y_votingpred[img_id] for img_id in unique_img_ids])\n",
    "\n",
    "# 计算准确度\n",
    "accuracy = accuracy_score(y_test_matched, y_votingpred_matched)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7445c28c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:43:08.202989Z",
     "iopub.status.busy": "2023-11-28T03:43:08.202705Z",
     "iopub.status.idle": "2023-11-28T03:43:08.211931Z",
     "shell.execute_reply": "2023-11-28T03:43:08.210792Z"
    },
    "papermill": {
     "duration": 0.0623,
     "end_time": "2023-11-28T03:43:08.213958",
     "exception": false,
     "start_time": "2023-11-28T03:43:08.151658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平衡准确率: 0.4547902336384498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# 计算平衡准确率\n",
    "balanced_acc = balanced_accuracy_score(y_test_matched, y_votingpred_matched)\n",
    "\n",
    "print(\"平衡准确率:\", balanced_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97ab3fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:43:08.316639Z",
     "iopub.status.busy": "2023-11-28T03:43:08.316331Z",
     "iopub.status.idle": "2023-11-28T03:43:08.323592Z",
     "shell.execute_reply": "2023-11-28T03:43:08.322525Z"
    },
    "papermill": {
     "duration": 0.06149,
     "end_time": "2023-11-28T03:43:08.325555",
     "exception": false,
     "start_time": "2023-11-28T03:43:08.264065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Metrics Evaluation on Test Data-----\n",
      "\n",
      "Confusion Matrix:\n",
      " [[117   2   8  21   3]\n",
      " [ 14   6   0  13   1]\n",
      " [ 45   1  21  15   7]\n",
      " [ 18   1   1  41   2]\n",
      " [ 14   1   6   1  17]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"-----Metrics Evaluation on Test Data-----\")\n",
    "print()\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test_matched, y_votingpred_matched))\n",
    "print()\n",
    "#print(\"Classification Report:\\n\",classification_report(y_test_matched, y_votingpred_matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de48272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T03:43:08.432120Z",
     "iopub.status.busy": "2023-11-28T03:43:08.431807Z",
     "iopub.status.idle": "2023-11-28T03:43:08.441635Z",
     "shell.execute_reply": "2023-11-28T03:43:08.440662Z"
    },
    "papermill": {
     "duration": 0.066119,
     "end_time": "2023-11-28T03:43:08.443616",
     "exception": false,
     "start_time": "2023-11-28T03:43:08.377497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_losses = []\\ntrain_accuracies = []\\nval_losses = []\\nval_accuracies = []\\n\\nnum_epochs = 100\\nfor epoch in range(num_epochs):\\n    combine_model.train()\\n    train_loss = 0.0\\n    train_acc = 0.0\\n\\n    for images, labels in train_loader:\\n        optimizer.zero_grad()\\n        images = images.to(device)\\n        labels = labels.to(device)\\n\\n        #few steps are hidden related to model structure\\n        output = output.max(dim=1)[0]\\n        loss = criterion(output, labels)\\n        loss.backward()\\n        optimizer.step()\\n\\n        train_loss += loss.item() * images.size(0)\\n        _, predictions = torch.max(output, 1)\\n        train_acc += torch.sum(predictions == labels.data)\\n\\n    train_loss = train_loss / len(train_loader.dataset)\\n    train_acc = train_acc.double() / len(train_loader.dataset)\\n\\n    # Validation\\n    combine_model.eval()\\n    val_loss = 0.0\\n    val_acc = 0.0\\n\\n    with torch.no_grad():\\n        for images, labels in val_loader:\\n            images = images.to(device)\\n            labels = labels.to(device)\\n\\n            #few steps are hidden related to model structure\\n            output = output.max(dim=1)[0]\\n            loss = criterion(output, labels)\\n\\n            val_loss += loss.item() * images.size(0)\\n            _, predictions = torch.max(output, 1)\\n            val_acc += torch.sum(predictions == labels.data)\\n\\n        val_loss = val_loss / len(val_loader.dataset)\\n        val_acc = val_acc.double() / len(val_loader.dataset)\\n\\n    # Append loss and accuracy to lists\\n    train_losses.append(train_loss)\\n    train_accuracies.append(train_acc.item())\\n    val_losses.append(val_loss)\\n    val_accuracies.append(val_acc.item())\\n\\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\\n    print(f\"Train Loss: {train_loss:.4f} Train Acc: {train_acc:.4f}\")\\n    print(f\"Val Loss: {val_loss:.4f} Val Acc: {val_acc:.4f}\")\\n\\n# Plotting the loss and accuracy\\nplt.figure(figsize=(12, 4))\\nplt.subplot(1, 2, 1)\\nplt.plot(range(1, num_epochs+1), train_losses, label=\\'Train Loss\\')\\nplt.plot(range(1, num_epochs+1), val_losses, label=\\'Validation Loss\\')\\nplt.xlabel(\\'Epoch\\',fontweight=\\'bold\\',fontsize=25)\\nplt.ylabel(\\'Loss\\',fontweight=\\'bold\\',fontsize=25)\\nplt.xticks(fontweight=\\'bold\\',fontsize=25)\\nplt.yticks(fontweight=\\'bold\\',fontsize=25)\\n# plt.title(\\'Training and Validation Loss\\')\\nplt.legend()\\nplt.savefig(\"/root/breast/UBC/LossPlots.png\",dpi=500)\\nplt.savefig(\"/root/breast/UBC/LossPlots.eps\",dpi=500)\\nplt.subplot(1, 2, 2)\\nplt.plot(range(1, num_epochs+1), train_accuracies, label=\\'Train Accuracy\\')\\nplt.plot(range(1, num_epochs+1), val_accuracies, label=\\'Validation Accuracy\\')\\nplt.xlabel(\\'Epoch\\',fontweight=\\'bold\\',fontsize=25)\\nplt.ylabel(\\'Accuracy\\',fontweight=\\'bold\\',fontsize=25)\\nplt.xticks(fontweight=\\'bold\\',fontsize=25)\\nplt.yticks(fontweight=\\'bold\\',fontsize=25)\\n# plt.title(\\'Training and Validation Accuracy\\')\\nplt.legend()\\nplt.tight_layout()\\nplt.savefig(\"/root/breast/UBC/AccPlots.png\",dpi=500)\\nplt.savefig(\"/root/breast/UBC/AccPlots.eps\",dpi=500)\\nplt.show()'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    combine_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #few steps are hidden related to model structure\n",
    "        output = output.max(dim=1)[0]\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        train_acc += torch.sum(predictions == labels.data)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = train_acc.double() / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    combine_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #few steps are hidden related to model structure\n",
    "            output = output.max(dim=1)[0]\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predictions = torch.max(output, 1)\n",
    "            val_acc += torch.sum(predictions == labels.data)\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_acc.double() / len(val_loader.dataset)\n",
    "\n",
    "    # Append loss and accuracy to lists\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc.item())\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Plotting the loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch',fontweight='bold',fontsize=25)\n",
    "plt.ylabel('Loss',fontweight='bold',fontsize=25)\n",
    "plt.xticks(fontweight='bold',fontsize=25)\n",
    "plt.yticks(fontweight='bold',fontsize=25)\n",
    "# plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"/root/breast/UBC/LossPlots.png\",dpi=500)\n",
    "plt.savefig(\"/root/breast/UBC/LossPlots.eps\",dpi=500)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, num_epochs+1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch',fontweight='bold',fontsize=25)\n",
    "plt.ylabel('Accuracy',fontweight='bold',fontsize=25)\n",
    "plt.xticks(fontweight='bold',fontsize=25)\n",
    "plt.yticks(fontweight='bold',fontsize=25)\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/root/breast/UBC/AccPlots.png\",dpi=500)\n",
    "plt.savefig(\"/root/breast/UBC/AccPlots.eps\",dpi=500)\n",
    "plt.show()'''"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6924515,
     "sourceId": 45867,
     "sourceType": "competition"
    },
    {
     "sourceId": 152272046,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 410.85607,
   "end_time": "2023-11-28T03:43:11.490314",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-28T03:36:20.634244",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
